<!DOCTYPE html>
<html lang="zh">

<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
    <meta content="yes" name="apple-mobile-web-app-capable" />
    <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style" />
    <meta content="telephone=no" name="format-detection" />
    <title>
Jupyter notebook test | 东坡烟尘    </title>
    <link rel="stylesheet" type="text/css" href="/theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/pygment.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css" />
    <link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css" />
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
    <link rel="Shortcut Icon" type="image/x-icon" href="/theme/favicon.ico" />
</head>

<body>
<div class="body_container">
    <div id="header">
        <div class="site-name">
            <a id="logo" href="/."> 东坡烟尘 </a>
            <p class="description"> 静能生悟，即鸟啼花落，都是化机。 </p>
        </div>
        <div id="nav-menu">
            <a href="/"><i class="fa fa-home"> 首页</i></a>
            <a href="/archives.html"><i class="fa fa-archive"> 归档</i></a>
            <a href="/about.html"><i class="fa fa-id-card"> 关于</i></a>
        </div>
    </div>
    <div id="layout" class="pure-g">
        <div class="pure-u-1 pure-u-md-3-4"><div class="content_container">
<div class="post">
    <h1 class="post-title">Jupyter notebook test</h1>
    <div class="post-meta"> 7 10, 2018
    <span> | </span> <span>posts</span>
    </div>
    <div class="post-content">
        <style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style>
<style type="text/css">
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="一、实现-Softmax-Regression-识别手写数字">一、实现 Softmax Regression 识别手写数字<a class="anchor-link" href="#一、实现-Softmax-Regression-识别手写数字">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="k">import</span> <span class="n">input_data</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">"MNIST_data/"</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'训练集的图片和标签：'</span><span class="p">,</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'测试集的图片和标签：'</span><span class="p">,</span><span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'验证集的图片和标签：'</span><span class="p">,</span><span class="n">mnist</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>    <span class="c1"># 在session里运算</span>

<span class="c1"># 定义网络结构，公式：y=softmax(Wx+b)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>   <span class="c1"># x表示输入量，其格式为float32型，None-不限输入的行数，784-输入的列数</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span><span class="mi">10</span><span class="p">]))</span>   <span class="c1"># 输出可能是0-9这10个数字</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># 定义损失函数及优化器</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>     <span class="c1"># y_ 表示真实的概率分布</span>
<span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y_</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>     <span class="c1"># 使用cross_entropy作为loss_function</span>
<span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>  <span class="c1"># 定义优化器</span>

<span class="c1"># 初始化</span>
<span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># 执行训练操作（此时才开始计算）</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 从训练集随机取100条，梯度下降</span>
    <span class="n">train_step</span><span class="o">.</span><span class="n">run</span><span class="p">({</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span>
        <span class="n">y_</span><span class="p">:</span> <span class="n">batch_ys</span>
    <span class="p">})</span> 
    
<span class="c1"># 计算准确率</span>
<span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>   <span class="c1"># 定义判断函数：检查张量中最大的分量和真实的y_中的分量是否一致</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>  <span class="c1">#定义评测流程： bool 转 float，并计算平均值，得到准确率</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">({</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
    <span class="n">y_</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span>
<span class="p">})</span>      <span class="c1"># 把测试集输入给评测流程</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ModuleNotFoundError</span>                       Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-a3439655ea68&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">from</span> tensorflow<span class="ansi-blue-fg">.</span>examples<span class="ansi-blue-fg">.</span>tutorials<span class="ansi-blue-fg">.</span>mnist <span class="ansi-green-fg">import</span> input_data
<span class="ansi-green-intense-fg ansi-bold">      2</span> mnist <span class="ansi-blue-fg">=</span> input_data<span class="ansi-blue-fg">.</span>read_data_sets<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"MNIST_data/"</span><span class="ansi-blue-fg">,</span> one_hot<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'训练集的图片和标签：'</span><span class="ansi-blue-fg">,</span>mnist<span class="ansi-blue-fg">.</span>train<span class="ansi-blue-fg">.</span>images<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">,</span> mnist<span class="ansi-blue-fg">.</span>train<span class="ansi-blue-fg">.</span>labels<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'测试集的图片和标签：'</span><span class="ansi-blue-fg">,</span>mnist<span class="ansi-blue-fg">.</span>test<span class="ansi-blue-fg">.</span>images<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">,</span> mnist<span class="ansi-blue-fg">.</span>test<span class="ansi-blue-fg">.</span>labels<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'验证集的图片和标签：'</span><span class="ansi-blue-fg">,</span>mnist<span class="ansi-blue-fg">.</span>validation<span class="ansi-blue-fg">.</span>images<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">,</span> mnist<span class="ansi-blue-fg">.</span>validation<span class="ansi-blue-fg">.</span>labels<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">ModuleNotFoundError</span>: No module named 'tensorflow'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="二、实现自编码器（无监督学习：提取高阶特征，并根据高阶特征重构数据）">二、实现自编码器（无监督学习：提取高阶特征，并根据高阶特征重构数据）<a class="anchor-link" href="#二、实现自编码器（无监督学习：提取高阶特征，并根据高阶特征重构数据）">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn.preprocessing</span> <span class="k">as</span> <span class="nn">prep</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="k">import</span> <span class="n">input_data</span>

<span class="c1"># 定义 Xavier 初始化器，让权重初始值满足标准均匀分布</span>
<span class="k">def</span> <span class="nf">xavier_init</span><span class="p">(</span><span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span><span class="p">,</span> <span class="n">constant</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    params:</span>
<span class="sd">    fan_in: 输入节点的数量</span>
<span class="sd">    fan_out: 输出节点的数量</span>
<span class="sd">    """</span>
    <span class="n">low</span> <span class="o">=</span> <span class="o">-</span><span class="n">constant</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">6.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">fan_in</span> <span class="o">+</span> <span class="n">fan_out</span><span class="p">))</span>
    <span class="n">high</span> <span class="o">=</span> <span class="n">constant</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">6.0</span> <span class="o">/</span><span class="p">(</span><span class="n">fan_in</span> <span class="o">+</span> <span class="n">fan_out</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">((</span><span class="n">fan_in</span><span class="p">,</span><span class="n">fan_out</span><span class="p">),</span> <span class="n">minval</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="n">high</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


<span class="c1"># 定义去噪自编码的类</span>
<span class="k">class</span> <span class="nc">AdditiveGaussianNoiseAutoencoder</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_input</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">transfer_function</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_input</span> <span class="o">=</span> <span class="n">n_input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transfer</span> <span class="o">=</span> <span class="n">transfer_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="n">network_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">network_weights</span>
        
        <span class="c1"># 定义网络结构（包含 1 个隐含层）</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_input</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transfer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">((</span><span class="n">n_input</span><span class="p">,)),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">'w1'</span><span class="p">]),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">'b1'</span><span class="p">]</span>
        <span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reconstruction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">'w2'</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">'b2'</span><span class="p">])</span>
        
        <span class="c1"># 定义损失函数及优化器</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cost</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reconstruction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">),</span> <span class="mf">2.0</span>
        <span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="p">)</span>
        
       <span class="c1"># 初始化 </span>
        <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span> <span class="n">global_variables_initializer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">all_weights</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">all_weights</span><span class="p">[</span><span class="s1">'w1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">xavier_init</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">))</span>
        <span class="n">all_weights</span><span class="p">[</span><span class="s1">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">all_weights</span><span class="p">[</span><span class="s1">'w2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_input</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">all_weights</span><span class="p">[</span><span class="s1">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_input</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">all_weights</span>
    
    <span class="k">def</span> <span class="nf">partial_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>   <span class="c1"># 执行单步训练，并返回当前的损失cost</span>
        <span class="n">cost</span><span class="p">,</span> <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">),</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_scale</span> <span class="p">})</span>
        <span class="k">return</span> <span class="n">cost</span>
    
    <span class="k">def</span> <span class="nf">calc_total_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cost</span><span class="p">,</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_scale</span> <span class="p">})</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>   <span class="c1"># 返回编码器隐含层的输出结果，获取抽象后的高阶特征</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span> <span class="n">feed_dict</span> <span class="o">=</span>  <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_scale</span> <span class="p">})</span>
        
    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>  <span class="c1"># 由高阶特征重构原始数据</span>
        <span class="k">if</span> <span class="n">hidden</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">'b1'</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reconstruction</span><span class="p">,</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">:</span> <span class="n">hidden</span><span class="p">})</span>
    
    <span class="k">def</span> <span class="nf">reconstruct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span> <span class="c1"># 整体运行一遍 transform 和 generate </span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reconstruction</span><span class="p">,</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_scale</span><span class="p">})</span>
    
    <span class="k">def</span> <span class="nf">getWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>    <span class="c1"># 隐含层的权重</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">'w1'</span><span class="p">])</span>
    
    <span class="k">def</span> <span class="nf">getBiases</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>    <span class="c1"># 隐含层的偏置系数</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="s1">'b1'</span><span class="p">])</span>
    

<span class="c1"># 数据标准化（均值为0，方差为1）</span>
<span class="k">def</span> <span class="nf">standard_scale</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
    <span class="n">preprocessor</span> <span class="o">=</span> <span class="n">prep</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span>

<span class="c1"># 不放回的随机抽样</span>
<span class="k">def</span> <span class="nf">get_random_block_from_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="n">start_index</span><span class="p">:(</span><span class="n">start_index</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">)]</span>


<span class="c1">#==============================================================</span>
<span class="c1"># 数据定义</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s1">'MNIST_data'</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">standard_scale</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">)</span> <span class="c1"># 对训练集、测试集进行标准化变换</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_examples</span><span class="p">)</span>   <span class="c1"># 总训练样本数</span>
<span class="n">training_epochs</span> <span class="o">=</span> <span class="mi">20</span>   <span class="c1"># 最大训练轮数</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="mi">1</span>   <span class="c1"># 每几轮显示一次损失</span>

<span class="c1"># 自编码器的实例（包含了网络结果、损失函数、优化器、误差计算方法等的定义）</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">AdditiveGaussianNoiseAutoencoder</span><span class="p">(</span><span class="n">n_input</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">transfer_function</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">,</span> 
                                               <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># 训练过程</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_epochs</span><span class="p">):</span>
    <span class="n">avg_cost</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">total_batch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_batch</span><span class="p">):</span>
        <span class="n">batch_xs</span> <span class="o">=</span> <span class="n">get_random_block_from_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">batch_xs</span><span class="p">)</span>
        <span class="n">avg_cost</span> <span class="o">+=</span> <span class="n">cost</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">batch_size</span>
        
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"计算轮数:"</span><span class="p">,</span> <span class="s1">'</span><span class="si">%04d</span><span class="s1">'</span> <span class="o">%</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="s2">"损失 cost="</span><span class="p">,</span> <span class="s2">"</span><span class="si">{:.9f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_cost</span><span class="p">))</span>

<span class="c1"># 对测试集进行测试，计算平方误差</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"测试集上的总损失 Total cost: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">calc_total_cost</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="三、实现多层感知机（此例只包含1个隐含层，与Softmax-Regression对比）">三、实现多层感知机（此例只包含1个隐含层，与Softmax Regression对比）<a class="anchor-link" href="#三、实现多层感知机（此例只包含1个隐含层，与Softmax-Regression对比）">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="k">import</span> <span class="n">input_data</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">"MNIST_data/"</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>

<span class="n">in_units</span> <span class="o">=</span> <span class="mi">784</span>   <span class="c1"># 输入节点数</span>
<span class="n">h1_units</span> <span class="o">=</span> <span class="mi">300</span>  <span class="c1"># 隐含层节点数</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">in_units</span><span class="p">,</span> <span class="n">h1_units</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>  <span class="c1"># 初始权重：阶段的正态分布，标准差为0.1</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">h1_units</span><span class="p">]))</span>
<span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">h1_units</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">in_units</span><span class="p">])</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>   <span class="c1"># 保留节点的概率：训练时小于1，以制造随机性，防止过拟合；预测时等于1，即全部特征都采用</span>
<span class="n">hidden1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>
<span class="n">hidden1_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">hidden1</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden1_drop</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span><span class="p">)</span>

<span class="c1"># 定义损失函数及优化器</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>     <span class="c1"># y_ 表示真实的概率分布</span>
<span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y_</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>     <span class="c1"># 使用cross_entropy作为loss_function</span>
<span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdagradOptimizer</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>  <span class="c1"># 和例一相比，换了个优化器</span>

<span class="c1"># 训练</span>
<span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3000</span><span class="p">):</span>     <span class="c1"># 一共30万的样本，相当于对训练集进行了5轮迭代</span>
    <span class="n">batch_xs</span><span class="p">,</span> <span class="n">batch_ys</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">train_step</span><span class="o">.</span><span class="n">run</span><span class="p">({</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">batch_xs</span><span class="p">,</span>
        <span class="n">y_</span><span class="p">:</span> <span class="n">batch_ys</span><span class="p">,</span>
        <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">0.75</span>
    <span class="p">})</span>
    
<span class="c1"># 计算准确率</span>
<span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>   <span class="c1"># 定义判断函数：检查张量中最大的分量和真实的y_中的分量是否一致</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>  <span class="c1">#定义评测流程： bool 转 float，并计算平均值，得到准确率</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">({</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
    <span class="n">y_</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="p">})</span>      <span class="c1"># 把测试集输入给评测流程</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'准确率：'</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="四、实现简单的卷积神经网络（CNN）（卷积的权值共享结构可大幅减少参数量，降低复杂度，防止过拟合）">四、实现简单的卷积神经网络（CNN）（卷积的权值共享结构可大幅减少参数量，降低复杂度，防止过拟合）<a class="anchor-link" href="#四、实现简单的卷积神经网络（CNN）（卷积的权值共享结构可大幅减少参数量，降低复杂度，防止过拟合）">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在CNN中，每一个卷积操作只处理一小块图像，提取最有效的特征往后传递。这种方法可以提取最基础的特征，比如拐角、边，而后再进行组合和抽象，形成更高阶的特征。CNN理论上具有对图像缩放、平移和旋转的不变性。</p>
<p>全连接神经网络 ---&gt;  局部连接神经网络</p>
<p>默认每个隐节点的参数完全一样  ---&gt;  参数量只跟卷积核的大小有关（权值共享）</p>
<p>CNN的要点：局部连接、权值共享、池化层中的降采样</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="k">import</span> <span class="n">input_data</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">"MNIST_data/"</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">weight_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
    <span class="n">initial</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># 带正态分布噪声的权重初值</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">bias_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
    <span class="n">initial</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># 偏置的初值（较小正值，如0.1，避免死亡节点）</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>  <span class="c1"># 二维卷积函数：x 输入，W 卷积的参数</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span>    <span class="c1"># strides 步长，padding 边界的处理方式</span>

<span class="k">def</span> <span class="nf">max_pool_2x2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="c1"># 最大池化函数</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">x_image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># 图片尺寸 28X28像素，-1代表样本数不固定，1代表颜色通道数量。CNN会利用空间结构信息。</span>

<span class="c1"># 定义第一个卷积层</span>
<span class="n">W_conv1</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">32</span><span class="p">])</span>   <span class="c1"># 卷积核尺寸5X5，1个颜色通道，32个不同的卷积核</span>
<span class="n">b_conv1</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">([</span><span class="mi">32</span><span class="p">])</span>
<span class="n">h_conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x_image</span><span class="p">,</span> <span class="n">W_conv1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_conv1</span><span class="p">)</span>
<span class="n">h_pool1</span> <span class="o">=</span> <span class="n">max_pool_2x2</span><span class="p">(</span><span class="n">h_conv1</span><span class="p">)</span>
    
<span class="c1"># 定义第二个卷积层，与第一个卷积层的不同之处在于卷积核变成64个</span>
<span class="n">W_conv2</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">])</span> 
<span class="n">b_conv2</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">([</span><span class="mi">64</span><span class="p">])</span>
<span class="n">h_conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2d</span><span class="p">(</span><span class="n">h_pool1</span><span class="p">,</span> <span class="n">W_conv2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_conv2</span><span class="p">)</span>
<span class="n">h_pool2</span> <span class="o">=</span> <span class="n">max_pool_2x2</span><span class="p">(</span><span class="n">h_conv2</span><span class="p">)</span>

<span class="c1"># 前面经历了两次步长为2X2的池化，故边长只有1/4了。即图片变成 7X7。</span>
<span class="c1"># 第2个卷积层有64个卷积核，故输出的tensor尺寸为 7X7X64</span>
<span class="c1"># 将其转换成一维向量，然后连接一个全连接层，隐含节点数1024</span>
<span class="n">W_fc1</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">([</span><span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1024</span><span class="p">])</span>
<span class="n">b_fc1</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">([</span><span class="mi">1024</span><span class="p">])</span>
<span class="n">h_pool2_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h_pool2</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="o">*</span><span class="mi">7</span><span class="o">*</span><span class="mi">64</span><span class="p">])</span>
<span class="n">h_fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">h_pool2_flat</span><span class="p">,</span> <span class="n">W_fc1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_fc1</span><span class="p">)</span>   <span class="c1"># ReLU 激活函数</span>

<span class="c1"># 为减轻过拟合，下面使用一个 Dropout 层</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">h_fc1_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_fc1</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

<span class="c1"># 再连接至 Softmax 层，得到最后的概率输出</span>
<span class="n">W_fc2</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">([</span><span class="mi">1024</span><span class="p">,</span><span class="mi">10</span><span class="p">])</span>
<span class="n">b_fc2</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
<span class="n">y_conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">h_fc1_drop</span><span class="p">,</span> <span class="n">W_fc2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_fc2</span><span class="p">)</span>



<span class="c1">#===================</span>
<span class="c1"># 定义损失函数及优化器</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>     <span class="c1"># y_ 表示真实的概率分布</span>
<span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">y_</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_conv</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>     <span class="c1"># 使用cross_entropy作为loss_function</span>
<span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>   <span class="c1"># 定义一个较小的学习速率</span>

<span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_conv</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>   <span class="c1"># 定义判断函数：检查张量中最大的分量和真实的y_中的分量是否一致</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>  <span class="c1">#定义评测流程： bool 转 float，并计算平均值，得到准确率</span>

<span class="c1"># 训练</span>
<span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20000</span><span class="p">):</span>     <span class="c1"># 一共100万的样本</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="k">100</span> == 0:
        <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
            <span class="n">x</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">y_</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span>
        <span class="p">})</span>
        <span class="nb">print</span> <span class="p">(</span><span class="s1">'第</span><span class="si">%d</span><span class="s1">次迭代'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="s1">'，准确率：</span><span class="si">%g</span><span class="s1">'</span> <span class="o">%</span> <span class="n">train_accuracy</span><span class="p">)</span>
    <span class="n">train_step</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">y_</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">0.5</span>
    <span class="p">})</span>
    
<span class="c1"># 计算最终准确率</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">({</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span>
    <span class="n">y_</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span>
<span class="p">})</span>      <span class="c1"># 把测试集输入给评测流程</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'最终准确率：'</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="五、实现进阶的卷积神经网络（针对CIFAR-10数据集）">五、实现进阶的卷积神经网络（针对CIFAR-10数据集）<a class="anchor-link" href="#五、实现进阶的卷积神经网络（针对CIFAR-10数据集）">¶</a></h3><p>数据增强（给单幅图增加多个变换的副本）大大增加了样本量，而数据量的大小恰恰是深度学习最看重的，深度学习可以在图像识别上领先其他算法的一大因素就是它对海量数据的利用率非常高。用其他算法，可能数据量大到一定程度时，准确率就不再提升了，而深度学习只要提供足够多的样本，准确率基本可以持续提升，所以说它是最适合大数据的算法。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'/Users/yg/git/models/tutorials/image/cifar10'</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">cifar10</span><span class="o">,</span> <span class="nn">cifar10_input</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>


<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">3000</span>  <span class="c1"># 训练轮数</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">'/tmp/cifar10_data/cifar-10-batches-bin'</span>

<span class="k">def</span> <span class="nf">variable_with_weight_loss</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">stddev</span><span class="p">,</span> <span class="n">wl</span><span class="p">):</span>  <span class="c1"># 加上loss，减少特征权重，防止过拟合</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">stddev</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">wl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weight_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_loss</span><span class="p">(</span><span class="n">var</span><span class="p">),</span> <span class="n">wl</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'weight_loss'</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s1">'losses'</span><span class="p">,</span> <span class="n">weight_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">var</span>


<span class="n">tf</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_string</span><span class="p">(</span><span class="s1">'f'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="s1">'kernel'</span><span class="p">)</span>  <span class="c1"># 解决下载时出现的错误</span>
<span class="n">cifar10</span><span class="o">.</span><span class="n">maybe_download_and_extract</span><span class="p">()</span>   <span class="c1"># 下载数据集并解压</span>

<span class="n">images_train</span><span class="p">,</span> <span class="n">labels_train</span><span class="o">=</span> <span class="n">cifar10_input</span><span class="o">.</span><span class="n">distorted_inputs</span><span class="p">(</span><span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">image_test</span><span class="p">,</span> <span class="n">labels_test</span> <span class="o">=</span> <span class="n">cifar10_input</span><span class="o">.</span><span class="n">inputs</span><span class="p">(</span><span class="n">eval_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">image_holder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>    <span class="c1"># 24X24像素，3颜色通道</span>
<span class="n">label_holder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>

<span class="c1"># 卷积层1</span>
<span class="n">weight1</span> <span class="o">=</span> <span class="n">variable_with_weight_loss</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">64</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">,</span> <span class="n">wl</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">kernel1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">image_holder</span><span class="p">,</span> <span class="n">weight1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span>
<span class="n">bias1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]))</span>
<span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">kernel1</span><span class="p">,</span> <span class="n">bias1</span><span class="p">))</span>
<span class="n">pool1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span>  <span class="c1"># 先使用最大池化层，再进行LRN层处理</span>
<span class="n">norm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">lrn</span><span class="p">(</span><span class="n">pool1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span> <span class="o">/</span> <span class="mf">9.0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>

<span class="c1"># 卷积层2</span>
<span class="n">weight2</span> <span class="o">=</span> <span class="n">variable_with_weight_loss</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">,</span> <span class="n">wl</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">kernel2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">norm1</span><span class="p">,</span> <span class="n">weight2</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span>
<span class="n">bias2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">]))</span>
<span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">kernel2</span><span class="p">,</span> <span class="n">bias2</span><span class="p">))</span>
<span class="n">norm2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">lrn</span><span class="p">(</span><span class="n">conv2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span> <span class="o">/</span> <span class="mf">9.0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>                 <span class="c1"># 先进行LRN层处理，再使用最大池化层</span>
<span class="n">pool2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">norm2</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">padding</span><span class="o">=</span><span class="s1">'SAME'</span><span class="p">)</span>

<span class="c1"># 全连接层，384个隐含节点</span>
<span class="n">reshape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pool2</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">dim</span> <span class="o">=</span> <span class="n">reshape</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
<span class="n">weight3</span> <span class="o">=</span> <span class="n">variable_with_weight_loss</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">dim</span><span class="p">,</span> <span class="mi">384</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.04</span><span class="p">,</span> <span class="n">wl</span><span class="o">=</span><span class="mf">0.004</span><span class="p">)</span>
<span class="n">bias3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">384</span><span class="p">]))</span>
<span class="n">local3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">reshape</span><span class="p">,</span> <span class="n">weight3</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias3</span><span class="p">)</span>

<span class="c1"># 全连接层，192个隐含节点</span>
<span class="n">weight4</span> <span class="o">=</span> <span class="n">variable_with_weight_loss</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">384</span><span class="p">,</span> <span class="mi">192</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.04</span><span class="p">,</span> <span class="n">wl</span><span class="o">=</span><span class="mf">0.004</span><span class="p">)</span>
<span class="n">bias4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">192</span><span class="p">]))</span>
<span class="n">local4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">local3</span><span class="p">,</span> <span class="n">weight4</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias4</span><span class="p">)</span>

<span class="c1"># 最后一层</span>
<span class="n">weight5</span> <span class="o">=</span> <span class="n">variable_with_weight_loss</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">192</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mf">192.0</span><span class="p">,</span> <span class="n">wl</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">bias5</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">local4</span><span class="p">,</span> <span class="n">weight5</span><span class="p">)</span> <span class="p">,</span> <span class="n">bias5</span><span class="p">)</span>


<span class="c1"># 损失计算函数</span>
<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'cross_entropy_per_example'</span><span class="p">)</span>
    <span class="n">cross_entropy_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'cross_entropy'</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s1">'losses'</span><span class="p">,</span> <span class="n">cross_entropy_mean</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">'losses'</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">'total_loss'</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label_holder</span><span class="p">)</span>
<span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">top_k_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">in_top_k</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label_holder</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

<span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">start_queue_runners</span><span class="p">()</span>   <span class="c1"># 启动图片数据增强的线程队列（16个线程）</span>

<span class="c1"># 开始训练</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">image_batch</span><span class="p">,</span> <span class="n">label_batch</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">images_train</span><span class="p">,</span> <span class="n">labels_train</span><span class="p">])</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">loss_value</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">train_op</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span>
                            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">image_holder</span><span class="p">:</span> <span class="n">image_batch</span><span class="p">,</span> <span class="n">label_holder</span><span class="p">:</span> <span class="n">label_batch</span><span class="p">})</span>
    <span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">examples_per_sec</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">/</span> <span class="n">duration</span>
        <span class="n">sec_per_patch</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">duration</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'迭代轮数：'</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="s1">' 损失值loss：'</span><span class="p">,</span> <span class="n">loss_value</span><span class="p">,</span> <span class="s1">' 样本处理速率：'</span> <span class="p">,</span> <span class="n">examples_per_sec</span><span class="p">,</span> <span class="s1">' examples/sec 迭代消耗时间：'</span><span class="p">,</span> <span class="n">sec_per_patch</span><span class="p">,</span> <span class="s1">'s'</span> <span class="p">)</span>
    
    
<span class="c1"># 在测试集上评价准确率</span>
<span class="n">num_examples</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="n">num_iter</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_examples</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>
<span class="n">true_count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_sample_count</span> <span class="o">=</span> <span class="n">num_iter</span> <span class="o">*</span> <span class="n">batch_size</span>
<span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">num_iter</span><span class="p">:</span>
    <span class="n">image_batch</span><span class="p">,</span> <span class="n">label_batch</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">image_test</span><span class="p">,</span> <span class="n">labels_test</span><span class="p">])</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">top_k_op</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span>
                          <span class="p">{</span>
                              <span class="n">image_holder</span><span class="p">:</span> <span class="n">image_batch</span><span class="p">,</span>
                              <span class="n">label_holder</span><span class="p">:</span> <span class="n">label_batch</span>
                          <span class="p">})</span>
    <span class="n">true_count</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="n">precision</span> <span class="o">=</span> <span class="n">true_count</span> <span class="o">/</span> <span class="n">total_sample_count</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'最终准确率：</span><span class="si">%.3f</span><span class="s1">'</span> <span class="o">%</span> <span class="n">precision</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
迭代轮数： 0  损失值loss： 4.67949  样本处理速率： 34.95589920409654  examples/sec 迭代消耗时间： 3.661756753921509 s
迭代轮数： 10  损失值loss： 3.63274  样本处理速率： 277.81763536387336  examples/sec 迭代消耗时间： 0.46073389053344727 s
迭代轮数： 20  损失值loss： 3.11208  样本处理速率： 259.8868673294972  examples/sec 迭代消耗时间： 0.4925220012664795 s
迭代轮数： 30  损失值loss： 2.77182  样本处理速率： 280.15928145087474  examples/sec 迭代消耗时间： 0.45688295364379883 s
迭代轮数： 40  损失值loss： 2.58904  样本处理速率： 282.0159332664457  examples/sec 迭代消耗时间： 0.4538750648498535 s
迭代轮数： 50  损失值loss： 2.47309  样本处理速率： 283.1381102183641  examples/sec 迭代消耗时间： 0.4520761966705322 s
迭代轮数： 60  损失值loss： 2.19007  样本处理速率： 278.55465004967976  examples/sec 迭代消耗时间： 0.459514856338501 s
迭代轮数： 70  损失值loss： 2.05387  样本处理速率： 280.5896161060581  examples/sec 迭代消耗时间： 0.45618224143981934 s
迭代轮数： 80  损失值loss： 2.1056  样本处理速率： 271.4879305471064  examples/sec 迭代消耗时间： 0.47147583961486816 s
迭代轮数： 90  损失值loss： 1.94307  样本处理速率： 282.0769808719483  examples/sec 迭代消耗时间： 0.45377683639526367 s
迭代轮数： 100  损失值loss： 1.95115  样本处理速率： 271.45100521695514  examples/sec 迭代消耗时间： 0.4715399742126465 s
迭代轮数： 110  损失值loss： 1.87197  样本处理速率： 278.04626414324326  examples/sec 迭代消耗时间： 0.4603550434112549 s
迭代轮数： 120  损失值loss： 2.04657  样本处理速率： 282.66554626273154  examples/sec 迭代消耗时间： 0.4528319835662842 s
迭代轮数： 130  损失值loss： 1.96598  样本处理速率： 278.7474387490836  examples/sec 迭代消耗时间： 0.4591970443725586 s
迭代轮数： 140  损失值loss： 1.71932  样本处理速率： 276.3516882868201  examples/sec 迭代消耗时间： 0.4631779193878174 s
迭代轮数： 150  损失值loss： 1.84175  样本处理速率： 279.66207031988637  examples/sec 迭代消耗时间： 0.45769524574279785 s
迭代轮数： 160  损失值loss： 1.78139  样本处理速率： 281.6673427608778  examples/sec 迭代消耗时间： 0.4544367790222168 s
迭代轮数： 170  损失值loss： 1.67361  样本处理速率： 280.4623841900289  examples/sec 迭代消耗时间： 0.4563891887664795 s
迭代轮数： 180  损失值loss： 1.56877  样本处理速率： 274.1551549987387  examples/sec 迭代消耗时间： 0.4668889045715332 s
迭代轮数： 190  损失值loss： 1.62189  样本处理速率： 283.1006350994202  examples/sec 迭代消耗时间： 0.4521360397338867 s
迭代轮数： 200  损失值loss： 1.81276  样本处理速率： 274.2737849227583  examples/sec 迭代消耗时间： 0.4666869640350342 s
迭代轮数： 210  损失值loss： 1.78851  样本处理速率： 279.27902261091396  examples/sec 迭代消耗时间： 0.45832300186157227 s
迭代轮数： 220  损失值loss： 1.54379  样本处理速率： 280.29721363522214  examples/sec 迭代消耗时间： 0.45665812492370605 s
迭代轮数： 230  损失值loss： 1.74025  样本处理速率： 275.5841077551691  examples/sec 迭代消耗时间： 0.46446800231933594 s
迭代轮数： 240  损失值loss： 1.60335  样本处理速率： 269.9464814298033  examples/sec 迭代消耗时间： 0.474168062210083 s
迭代轮数： 250  损失值loss： 1.59062  样本处理速率： 280.1654218834148  examples/sec 迭代消耗时间： 0.45687294006347656 s
迭代轮数： 260  损失值loss： 1.66278  样本处理速率： 245.65264691455639  examples/sec 迭代消耗时间： 0.5210609436035156 s
迭代轮数： 270  损失值loss： 1.59492  样本处理速率： 277.82669278279025  examples/sec 迭代消耗时间： 0.46071887016296387 s
迭代轮数： 280  损失值loss： 1.63355  样本处理速率： 281.89184511858053  examples/sec 迭代消耗时间： 0.4540748596191406 s
迭代轮数： 290  损失值loss： 1.49821  样本处理速率： 278.02092235033365  examples/sec 迭代消耗时间： 0.46039700508117676 s
迭代轮数： 300  损失值loss： 1.49426  样本处理速率： 277.16375850082886  examples/sec 迭代消耗时间： 0.4618208408355713 s
迭代轮数： 310  损失值loss： 1.50426  样本处理速率： 281.3961401197034  examples/sec 迭代消耗时间： 0.45487475395202637 s
迭代轮数： 320  损失值loss： 1.66866  样本处理速率： 285.8477273901045  examples/sec 迭代消耗时间： 0.44779086112976074 s
迭代轮数： 330  损失值loss： 1.49512  样本处理速率： 225.3568113368719  examples/sec 迭代消耗时间： 0.5679881572723389 s
迭代轮数： 340  损失值loss： 1.44412  样本处理速率： 245.4886499358924  examples/sec 迭代消耗时间： 0.5214090347290039 s
迭代轮数： 350  损失值loss： 1.60949  样本处理速率： 280.59460219418156  examples/sec 迭代消耗时间： 0.4561741352081299 s
迭代轮数： 360  损失值loss： 1.55761  样本处理速率： 272.79554723139944  examples/sec 迭代消耗时间： 0.46921586990356445 s
迭代轮数： 370  损失值loss： 1.54588  样本处理速率： 270.33088097193473  examples/sec 迭代消耗时间： 0.4734938144683838 s
迭代轮数： 380  损失值loss： 1.45811  样本处理速率： 273.63172240853817  examples/sec 迭代消耗时间： 0.46778202056884766 s
迭代轮数： 390  损失值loss： 1.49796  样本处理速率： 278.6881129887429  examples/sec 迭代消耗时间： 0.45929479598999023 s
迭代轮数： 400  损失值loss： 1.47017  样本处理速率： 276.8625998131115  examples/sec 迭代消耗时间： 0.4623231887817383 s
迭代轮数： 410  损失值loss： 1.47259  样本处理速率： 280.7867014221579  examples/sec 迭代消耗时间： 0.45586204528808594 s
迭代轮数： 420  损失值loss： 1.56915  样本处理速率： 265.74255383075604  examples/sec 迭代消耗时间： 0.48166918754577637 s
迭代轮数： 430  损失值loss： 1.4875  样本处理速率： 279.68844072409314  examples/sec 迭代消耗时间： 0.45765209197998047 s
迭代轮数： 440  损失值loss： 1.53552  样本处理速率： 279.16444347380707  examples/sec 迭代消耗时间： 0.4585111141204834 s
迭代轮数： 450  损失值loss： 1.43824  样本处理速率： 214.68653507789756  examples/sec 迭代消耗时间： 0.5962181091308594 s
迭代轮数： 460  损失值loss： 1.51591  样本处理速率： 255.52772833108364  examples/sec 迭代消耗时间： 0.5009241104125977 s
迭代轮数： 470  损失值loss： 1.48821  样本处理速率： 267.10168374223315  examples/sec 迭代消耗时间： 0.4792182445526123 s
迭代轮数： 480  损失值loss： 1.54503  样本处理速率： 284.32947357271473  examples/sec 迭代消耗时间： 0.4501819610595703 s
迭代轮数： 490  损失值loss： 1.67588  样本处理速率： 278.3274934445114  examples/sec 迭代消耗时间： 0.45988988876342773 s
迭代轮数： 500  损失值loss： 1.46795  样本处理速率： 279.4547770408878  examples/sec 迭代消耗时间： 0.4580347537994385 s
迭代轮数： 510  损失值loss： 1.4559  样本处理速率： 232.9467217773813  examples/sec 迭代消耗时间： 0.5494818687438965 s
迭代轮数： 520  损失值loss： 1.42229  样本处理速率： 273.3843970475533  examples/sec 迭代消耗时间： 0.46820521354675293 s
迭代轮数： 530  损失值loss： 1.44433  样本处理速率： 237.0721186051862  examples/sec 迭代消耗时间： 0.5399200916290283 s
迭代轮数： 540  损失值loss： 1.46641  样本处理速率： 281.0667356327014  examples/sec 迭代消耗时间： 0.45540785789489746 s
迭代轮数： 550  损失值loss： 1.38305  样本处理速率： 252.90303664960928  examples/sec 迭代消耗时间： 0.5061228275299072 s
迭代轮数： 560  损失值loss： 1.40241  样本处理速率： 279.85056035696044  examples/sec 迭代消耗时间： 0.45738697052001953 s
迭代轮数： 570  损失值loss： 1.4708  样本处理速率： 276.0483164716553  examples/sec 迭代消耗时间： 0.4636869430541992 s
迭代轮数： 580  损失值loss： 1.37789  样本处理速率： 275.53248395548337  examples/sec 迭代消耗时间： 0.464555025100708 s
迭代轮数： 590  损失值loss： 1.41042  样本处理速率： 235.99115589623037  examples/sec 迭代消耗时间： 0.5423932075500488 s
迭代轮数： 600  损失值loss： 1.37464  样本处理速率： 281.114860675927  examples/sec 迭代消耗时间： 0.45532989501953125 s
迭代轮数： 610  损失值loss： 1.46781  样本处理速率： 283.86913711585174  examples/sec 迭代消耗时间： 0.4509119987487793 s
迭代轮数： 620  损失值loss： 1.35001  样本处理速率： 281.09749255200506  examples/sec 迭代消耗时间： 0.45535802841186523 s
迭代轮数： 630  损失值loss： 1.32239  样本处理速率： 282.0658658693369  examples/sec 迭代消耗时间： 0.4537947177886963 s
迭代轮数： 640  损失值loss： 1.39715  样本处理速率： 276.1352102012517  examples/sec 迭代消耗时间： 0.46354103088378906 s
迭代轮数： 650  损失值loss： 1.27919  样本处理速率： 282.4197524629557  examples/sec 迭代消耗时间： 0.45322608947753906 s
迭代轮数： 660  损失值loss： 1.40317  样本处理速率： 249.59873840969698  examples/sec 迭代消耗时间： 0.5128231048583984 s
迭代轮数： 670  损失值loss： 1.30235  样本处理速率： 197.4887922992487  examples/sec 迭代消耗时间： 0.6481380462646484 s
迭代轮数： 680  损失值loss： 1.38451  样本处理速率： 279.1043597017804  examples/sec 迭代消耗时间： 0.45860981941223145 s
迭代轮数： 690  损失值loss： 1.25527  样本处理速率： 255.5323499873869  examples/sec 迭代消耗时间： 0.5009150505065918 s
迭代轮数： 700  损失值loss： 1.32053  样本处理速率： 285.3486406272589  examples/sec 迭代消耗时间： 0.4485740661621094 s
迭代轮数： 710  损失值loss： 1.23065  样本处理速率： 257.173198696101  examples/sec 迭代消耗时间： 0.49771904945373535 s
迭代轮数： 720  损失值loss： 1.39564  样本处理速率： 283.2127914245547  examples/sec 迭代消耗时间： 0.45195698738098145 s
迭代轮数： 730  损失值loss： 1.32647  样本处理速率： 242.85856352391534  examples/sec 迭代消耗时间： 0.5270557403564453 s
迭代轮数： 740  损失值loss： 1.48244  样本处理速率： 204.94862340282012  examples/sec 迭代消耗时间： 0.6245467662811279 s
迭代轮数： 750  损失值loss： 1.36172  样本处理速率： 255.50231220942712  examples/sec 迭代消耗时间： 0.5009739398956299 s
迭代轮数： 760  损失值loss： 1.42245  样本处理速率： 271.03823618205627  examples/sec 迭代消耗时间： 0.4722580909729004 s
迭代轮数： 770  损失值loss： 1.28105  样本处理速率： 251.01923914934045  examples/sec 迭代消耗时间： 0.5099210739135742 s
迭代轮数： 780  损失值loss： 1.28252  样本处理速率： 273.6914261477412  examples/sec 迭代消耗时间： 0.4676799774169922 s
迭代轮数： 790  损失值loss： 1.38034  样本处理速率： 269.0635849390402  examples/sec 迭代消耗时间： 0.4757239818572998 s
迭代轮数： 800  损失值loss： 1.20561  样本处理速率： 240.4324130663668  examples/sec 迭代消耗时间： 0.5323741436004639 s
迭代轮数： 810  损失值loss： 1.37943  样本处理速率： 264.47051405331274  examples/sec 迭代消耗时间： 0.48398590087890625 s
迭代轮数： 820  损失值loss： 1.37976  样本处理速率： 217.17780257067662  examples/sec 迭代消耗时间： 0.589378833770752 s
迭代轮数： 830  损失值loss： 1.26944  样本处理速率： 254.04591434275486  examples/sec 迭代消耗时间： 0.5038459300994873 s
迭代轮数： 840  损失值loss： 1.37431  样本处理速率： 258.10245333207695  examples/sec 迭代消耗时间： 0.495927095413208 s
迭代轮数： 850  损失值loss： 1.50979  样本处理速率： 230.1975681518623  examples/sec 迭代消耗时间： 0.5560441017150879 s
迭代轮数： 860  损失值loss： 1.42455  样本处理速率： 273.7341275061363  examples/sec 迭代消耗时间： 0.4676070213317871 s
迭代轮数： 870  损失值loss： 1.1463  样本处理速率： 269.43952238014964  examples/sec 迭代消耗时间： 0.47506022453308105 s
迭代轮数： 880  损失值loss： 1.358  样本处理速率： 279.3813374187284  examples/sec 迭代消耗时间： 0.45815515518188477 s
迭代轮数： 890  损失值loss： 1.25253  样本处理速率： 268.40002719641006  examples/sec 迭代消耗时间： 0.4769001007080078 s
迭代轮数： 900  损失值loss： 1.39459  样本处理速率： 194.31652616049698  examples/sec 迭代消耗时间： 0.6587190628051758 s
迭代轮数： 910  损失值loss： 1.15612  样本处理速率： 280.8445734791775  examples/sec 迭代消耗时间： 0.4557681083679199 s
迭代轮数： 920  损失值loss： 1.50739  样本处理速率： 279.29006435100166  examples/sec 迭代消耗时间： 0.45830488204956055 s
迭代轮数： 930  损失值loss： 1.22217  样本处理速率： 278.9552779649762  examples/sec 迭代消耗时间： 0.45885491371154785 s
迭代轮数： 940  损失值loss： 1.13866  样本处理速率： 274.9588548308622  examples/sec 迭代消耗时间： 0.46552419662475586 s
迭代轮数： 950  损失值loss： 1.44205  样本处理速率： 261.7864722837024  examples/sec 迭代消耗时间： 0.48894810676574707 s
迭代轮数： 960  损失值loss： 1.36406  样本处理速率： 283.313075535601  examples/sec 迭代消耗时间： 0.4517970085144043 s
迭代轮数： 970  损失值loss： 1.41009  样本处理速率： 277.3564887834761  examples/sec 迭代消耗时间： 0.4614999294281006 s
迭代轮数： 980  损失值loss： 1.42782  样本处理速率： 272.5067061904859  examples/sec 迭代消耗时间： 0.4697132110595703 s
迭代轮数： 990  损失值loss： 1.4149  样本处理速率： 258.2002682658092  examples/sec 迭代消耗时间： 0.495739221572876 s
迭代轮数： 1000  损失值loss： 1.29364  样本处理速率： 275.73144797925505  examples/sec 迭代消耗时间： 0.4642198085784912 s
迭代轮数： 1010  损失值loss： 1.13944  样本处理速率： 282.6232862830524  examples/sec 迭代消耗时间： 0.452899694442749 s
迭代轮数： 1020  损失值loss： 1.15204  样本处理速率： 272.7420530171407  examples/sec 迭代消耗时间： 0.46930789947509766 s
迭代轮数： 1030  损失值loss： 1.17793  样本处理速率： 279.5595498269386  examples/sec 迭代消耗时间： 0.45786309242248535 s
迭代轮数： 1040  损失值loss： 1.23167  样本处理速率： 230.6431860986239  examples/sec 迭代消耗时间： 0.5549697875976562 s
迭代轮数： 1050  损失值loss： 1.33045  样本处理速率： 273.8266928420201  examples/sec 迭代消耗时间： 0.4674489498138428 s
迭代轮数： 1060  损失值loss： 1.15458  样本处理速率： 273.50027076414585  examples/sec 迭代消耗时间： 0.46800684928894043 s
迭代轮数： 1070  损失值loss： 1.16087  样本处理速率： 266.5449856890008  examples/sec 迭代消耗时间： 0.48021912574768066 s
迭代轮数： 1080  损失值loss： 1.18224  样本处理速率： 242.70463835546832  examples/sec 迭代消耗时间： 0.5273900032043457 s
迭代轮数： 1090  损失值loss： 1.30931  样本处理速率： 275.66915239337845  examples/sec 迭代消耗时间： 0.4643247127532959 s
迭代轮数： 1100  损失值loss： 1.22082  样本处理速率： 281.5608367461782  examples/sec 迭代消耗时间： 0.454608678817749 s
迭代轮数： 1110  损失值loss： 1.29665  样本处理速率： 260.21336422393426  examples/sec 迭代消耗时间： 0.49190402030944824 s
迭代轮数： 1120  损失值loss： 1.0391  样本处理速率： 277.983494062305  examples/sec 迭代消耗时间： 0.46045899391174316 s
迭代轮数： 1130  损失值loss： 1.34536  样本处理速率： 276.17214239711274  examples/sec 迭代消耗时间： 0.46347904205322266 s
迭代轮数： 1140  损失值loss： 1.16632  样本处理速率： 286.2012558566752  examples/sec 迭代消耗时间： 0.4472377300262451 s
迭代轮数： 1150  损失值loss： 1.31159  样本处理速率： 252.21085763384366  examples/sec 迭代消耗时间： 0.5075118541717529 s
迭代轮数： 1160  损失值loss： 1.23365  样本处理速率： 267.74814650791416  examples/sec 迭代消耗时间： 0.4780611991882324 s
迭代轮数： 1170  损失值loss： 1.30098  样本处理速率： 276.0185125965654  examples/sec 迭代消耗时间： 0.46373701095581055 s
迭代轮数： 1180  损失值loss： 1.38629  样本处理速率： 280.3740640200372  examples/sec 迭代消耗时间： 0.45653295516967773 s
迭代轮数： 1190  损失值loss： 1.3595  样本处理速率： 277.74045561421525  examples/sec 迭代消耗时间： 0.4608619213104248 s
迭代轮数： 1200  损失值loss： 1.33279  样本处理速率： 273.20076026084985  examples/sec 迭代消耗时间： 0.468519926071167 s
迭代轮数： 1210  损失值loss： 1.14821  样本处理速率： 263.4323488310016  examples/sec 迭代消耗时间： 0.48589324951171875 s
迭代轮数： 1220  损失值loss： 1.22561  样本处理速率： 267.41273599120166  examples/sec 迭代消耗时间： 0.47866082191467285 s
迭代轮数： 1230  损失值loss： 1.08933  样本处理速率： 249.38783651646378  examples/sec 迭代消耗时间： 0.5132567882537842 s
迭代轮数： 1240  损失值loss： 1.19405  样本处理速率： 274.41608004857875  examples/sec 迭代消耗时间： 0.4664449691772461 s
迭代轮数： 1250  损失值loss： 1.17669  样本处理速率： 260.4744452913382  examples/sec 迭代消耗时间： 0.4914109706878662 s
迭代轮数： 1260  损失值loss： 1.16564  样本处理速率： 262.73168253794256  examples/sec 迭代消耗时间： 0.48718905448913574 s
迭代轮数： 1270  损失值loss： 1.261  样本处理速率： 273.4790941946855  examples/sec 迭代消耗时间： 0.46804308891296387 s
迭代轮数： 1280  损失值loss： 1.2786  样本处理速率： 283.99196802444294  examples/sec 迭代消耗时间： 0.4507169723510742 s
迭代轮数： 1290  损失值loss： 1.46346  样本处理速率： 247.26032870963553  examples/sec 迭代消耗时间： 0.5176730155944824 s
迭代轮数： 1300  损失值loss： 1.11695  样本处理速率： 233.22055197507547  examples/sec 迭代消耗时间： 0.5488367080688477 s
迭代轮数： 1310  损失值loss： 1.2056  样本处理速率： 223.29521234782536  examples/sec 迭代消耗时间： 0.5732321739196777 s
迭代轮数： 1320  损失值loss： 1.43308  样本处理速率： 293.3425885047624  examples/sec 迭代消耗时间： 0.43634986877441406 s
迭代轮数： 1330  损失值loss： 1.05131  样本处理速率： 287.5577594453568  examples/sec 迭代消耗时间： 0.4451279640197754 s
迭代轮数： 1340  损失值loss： 1.19333  样本处理速率： 279.6071600810379  examples/sec 迭代消耗时间： 0.45778512954711914 s
迭代轮数： 1350  损失值loss： 1.16917  样本处理速率： 283.50891630779466  examples/sec 迭代消耗时间： 0.45148491859436035 s
迭代轮数： 1360  损失值loss： 1.09505  样本处理速率： 288.37531107170884  examples/sec 迭代消耗时间： 0.4438660144805908 s
迭代轮数： 1370  损失值loss： 1.19779  样本处理速率： 286.5200270685102  examples/sec 迭代消耗时间： 0.44674015045166016 s
迭代轮数： 1380  损失值loss： 1.22502  样本处理速率： 288.81900143583476  examples/sec 迭代消耗时间： 0.44318413734436035 s
迭代轮数： 1390  损失值loss： 1.12772  样本处理速率： 280.9117290794711  examples/sec 迭代消耗时间： 0.4556591510772705 s
迭代轮数： 1400  损失值loss： 1.30731  样本处理速率： 280.7953660239596  examples/sec 迭代消耗时间： 0.45584797859191895 s
迭代轮数： 1410  损失值loss： 1.38859  样本处理速率： 287.3312189519362  examples/sec 迭代消耗时间： 0.4454789161682129 s
迭代轮数： 1420  损失值loss： 1.1859  样本处理速率： 292.07275829220936  examples/sec 迭代消耗时间： 0.4382469654083252 s
迭代轮数： 1430  损失值loss： 1.10654  样本处理速率： 279.03792034020665  examples/sec 迭代消耗时间： 0.45871901512145996 s
迭代轮数： 1440  损失值loss： 1.20507  样本处理速率： 290.0429291114827  examples/sec 迭代消耗时间： 0.4413139820098877 s
迭代轮数： 1450  损失值loss： 1.14996  样本处理速率： 287.9748366409233  examples/sec 迭代消耗时间： 0.44448328018188477 s
迭代轮数： 1460  损失值loss： 1.16132  样本处理速率： 286.2888586592807  examples/sec 迭代消耗时间： 0.4471008777618408 s
迭代轮数： 1470  损失值loss： 1.21209  样本处理速率： 290.14622778658696  examples/sec 迭代消耗时间： 0.44115686416625977 s
迭代轮数： 1480  损失值loss： 1.12753  样本处理速率： 223.1667502184401  examples/sec 迭代消耗时间： 0.5735621452331543 s
迭代轮数： 1490  损失值loss： 0.864416  样本处理速率： 201.33071927974524  examples/sec 迭代消耗时间： 0.6357698440551758 s
迭代轮数： 1500  损失值loss： 1.24946  样本处理速率： 291.5704010409991  examples/sec 迭代消耗时间： 0.43900203704833984 s
迭代轮数： 1510  损失值loss： 1.2178  样本处理速率： 261.29975172988446  examples/sec 迭代消耗时间： 0.48985886573791504 s
迭代轮数： 1520  损失值loss： 1.22759  样本处理速率： 288.3748463779575  examples/sec 迭代消耗时间： 0.4438667297363281 s
迭代轮数： 1530  损失值loss： 1.12704  样本处理速率： 271.38431799938127  examples/sec 迭代消耗时间： 0.47165584564208984 s
迭代轮数： 1540  损失值loss： 1.07582  样本处理速率： 288.4644050347799  examples/sec 迭代消耗时间： 0.4437289237976074 s
迭代轮数： 1550  损失值loss： 1.25999  样本处理速率： 283.75091144525777  examples/sec 迭代消耗时间： 0.45109987258911133 s
迭代轮数： 1560  损失值loss： 1.07568  样本处理速率： 286.48730774854346  examples/sec 迭代消耗时间： 0.4467911720275879 s
迭代轮数： 1570  损失值loss： 1.20117  样本处理速率： 285.42570661177234  examples/sec 迭代消耗时间： 0.4484529495239258 s
迭代轮数： 1580  损失值loss： 1.25162  样本处理速率： 293.448732510459  examples/sec 迭代消耗时间： 0.43619203567504883 s
迭代轮数： 1590  损失值loss： 1.17017  样本处理速率： 287.6597576004372  examples/sec 迭代消耗时间： 0.44497013092041016 s
迭代轮数： 1600  损失值loss： 1.16566  样本处理速率： 286.3856809003101  examples/sec 迭代消耗时间： 0.44694972038269043 s
迭代轮数： 1610  损失值loss： 1.11749  样本处理速率： 290.781427110595  examples/sec 迭代消耗时间： 0.44019317626953125 s
迭代轮数： 1620  损失值loss： 1.12218  样本处理速率： 285.62052919004185  examples/sec 迭代消耗时间： 0.4481470584869385 s
迭代轮数： 1630  损失值loss： 1.04349  样本处理速率： 290.5788737875428  examples/sec 迭代消耗时间： 0.44050002098083496 s
迭代轮数： 1640  损失值loss： 1.20511  样本处理速率： 288.717421805719  examples/sec 迭代消耗时间： 0.4433400630950928 s
迭代轮数： 1650  损失值loss： 1.10279  样本处理速率： 288.52098890297503  examples/sec 迭代消耗时间： 0.44364190101623535 s
迭代轮数： 1660  损失值loss： 1.15249  样本处理速率： 292.1255212048695  examples/sec 迭代消耗时间： 0.4381678104400635 s
迭代轮数： 1670  损失值loss： 1.1806  样本处理速率： 292.17146588880667  examples/sec 迭代消耗时间： 0.4380989074707031 s
迭代轮数： 1680  损失值loss： 1.01927  样本处理速率： 286.45291465225483  examples/sec 迭代消耗时间： 0.44684481620788574 s
迭代轮数： 1690  损失值loss： 1.23218  样本处理速率： 288.4749450046371  examples/sec 迭代消耗时间： 0.4437127113342285 s
迭代轮数： 1700  损失值loss： 1.22289  样本处理速率： 292.5727040871935  examples/sec 迭代消耗时间： 0.4374980926513672 s
迭代轮数： 1710  损失值loss： 1.06788  样本处理速率： 288.27466240397257  examples/sec 迭代消耗时间： 0.44402098655700684 s
迭代轮数： 1720  损失值loss： 1.04394  样本处理速率： 284.9686230901317  examples/sec 迭代消耗时间： 0.4491722583770752 s
迭代轮数： 1730  损失值loss： 0.967943  样本处理速率： 290.08837773509157  examples/sec 迭代消耗时间： 0.44124484062194824 s
迭代轮数： 1740  损失值loss： 1.14268  样本处理速率： 287.65790804735656  examples/sec 迭代消耗时间： 0.4449729919433594 s
迭代轮数： 1750  损失值loss： 1.1489  样本处理速率： 285.9939090491159  examples/sec 迭代消耗时间： 0.44756197929382324 s
迭代轮数： 1760  损失值loss： 1.2101  样本处理速率： 290.80788847625524  examples/sec 迭代消耗时间： 0.4401531219482422 s
迭代轮数： 1770  损失值loss： 1.18103  样本处理速率： 289.70032926935875  examples/sec 迭代消耗时间： 0.441835880279541 s
迭代轮数： 1780  损失值loss： 1.13454  样本处理速率： 285.50220692559844  examples/sec 迭代消耗时间： 0.4483327865600586 s
迭代轮数： 1790  损失值loss： 1.3228  样本处理速率： 296.29504174239094  examples/sec 迭代消耗时间： 0.43200182914733887 s
迭代轮数： 1800  损失值loss： 1.08724  样本处理速率： 283.5924815660182  examples/sec 迭代消耗时间： 0.4513518810272217 s
迭代轮数： 1810  损失值loss： 0.970939  样本处理速率： 283.45473005400663  examples/sec 迭代消耗时间： 0.4515712261199951 s
迭代轮数： 1820  损失值loss： 1.251  样本处理速率： 288.34851617879116  examples/sec 迭代消耗时间： 0.4439072608947754 s
迭代轮数： 1830  损失值loss： 1.11315  样本处理速率： 290.27533693822676  examples/sec 迭代消耗时间： 0.4409606456756592 s
迭代轮数： 1840  损失值loss： 1.29171  样本处理速率： 284.40644195097815  examples/sec 迭代消耗时间： 0.4500601291656494 s
迭代轮数： 1850  损失值loss： 1.20754  样本处理速率： 284.99978606605197  examples/sec 迭代消耗时间： 0.4491231441497803 s
迭代轮数： 1860  损失值loss： 1.16635  样本处理速率： 288.55867211745493  examples/sec 迭代消耗时间： 0.44358396530151367 s
迭代轮数： 1870  损失值loss： 1.18328  样本处理速率： 288.19295641657277  examples/sec 迭代消耗时间： 0.44414687156677246 s
迭代轮数： 1880  损失值loss： 0.994796  样本处理速率： 292.08149781892683  examples/sec 迭代消耗时间： 0.4382338523864746 s
迭代轮数： 1890  损失值loss： 1.11467  样本处理速率： 283.2216064056181  examples/sec 迭代消耗时间： 0.45194292068481445 s
迭代轮数： 1900  损失值loss： 0.971728  样本处理速率： 285.83737852318046  examples/sec 迭代消耗时间： 0.44780707359313965 s
迭代轮数： 1910  损失值loss： 1.13724  样本处理速率： 288.8646889653521  examples/sec 迭代消耗时间： 0.4431140422821045 s
迭代轮数： 1920  损失值loss： 0.945922  样本处理速率： 288.4066038967353  examples/sec 迭代消耗时间： 0.4438178539276123 s
迭代轮数： 1930  损失值loss： 0.992418  样本处理速率： 290.60199497251335  examples/sec 迭代消耗时间： 0.44046497344970703 s
迭代轮数： 1940  损失值loss： 0.999599  样本处理速率： 294.3766635321082  examples/sec 迭代消耗时间： 0.4348170757293701 s
迭代轮数： 1950  损失值loss： 1.19207  样本处理速率： 269.49646357710304  examples/sec 迭代消耗时间： 0.4749598503112793 s
迭代轮数： 1960  损失值loss： 1.09356  样本处理速率： 285.90831373121244  examples/sec 迭代消耗时间： 0.4476959705352783 s
迭代轮数： 1970  损失值loss： 1.26574  样本处理速率： 284.9923728957516  examples/sec 迭代消耗时间： 0.44913482666015625 s
迭代轮数： 1980  损失值loss： 1.12312  样本处理速率： 288.5717007033812  examples/sec 迭代消耗时间： 0.44356393814086914 s
迭代轮数： 1990  损失值loss： 0.982787  样本处理速率： 290.96391938632496  examples/sec 迭代消耗时间： 0.43991708755493164 s
迭代轮数： 2000  损失值loss： 0.988682  样本处理速率： 287.0764801628976  examples/sec 迭代消耗时间： 0.4458742141723633 s
迭代轮数： 2010  损失值loss： 1.33379  样本处理速率： 284.7052205325533  examples/sec 迭代消耗时间： 0.4495878219604492 s
迭代轮数： 2020  损失值loss： 1.0595  样本处理速率： 293.8293650446159  examples/sec 迭代消耗时间： 0.4356269836425781 s
迭代轮数： 2030  损失值loss： 1.04234  样本处理速率： 286.1811178459506  examples/sec 迭代消耗时间： 0.4472692012786865 s
迭代轮数： 2040  损失值loss： 1.10227  样本处理速率： 287.28155706585574  examples/sec 迭代消耗时间： 0.4455559253692627 s
迭代轮数： 2050  损失值loss： 1.25638  样本处理速率： 285.803597732399  examples/sec 迭代消耗时间： 0.4478600025177002 s
迭代轮数： 2060  损失值loss： 1.09464  样本处理速率： 285.0134030978903  examples/sec 迭代消耗时间： 0.44910168647766113 s
迭代轮数： 2070  损失值loss： 1.18155  样本处理速率： 284.945784654448  examples/sec 迭代消耗时间： 0.44920825958251953 s
迭代轮数： 2080  损失值loss： 1.03183  样本处理速率： 292.197385701309  examples/sec 迭代消耗时间： 0.43806004524230957 s
迭代轮数： 2090  损失值loss： 1.07094  样本处理速率： 288.3616806773241  examples/sec 迭代消耗时间： 0.44388699531555176 s
迭代轮数： 2100  损失值loss： 1.03642  样本处理速率： 288.1538220423586  examples/sec 迭代消耗时间： 0.44420719146728516 s
迭代轮数： 2110  损失值loss： 1.19056  样本处理速率： 286.78266369238395  examples/sec 迭代消耗时间： 0.4463310241699219 s
迭代轮数： 2120  损失值loss： 1.09381  样本处理速率： 288.71307442575574  examples/sec 迭代消耗时间： 0.4433467388153076 s
迭代轮数： 2130  损失值loss： 0.934  样本处理速率： 289.51535878876905  examples/sec 迭代消耗时间： 0.44211816787719727 s
迭代轮数： 2140  损失值loss： 0.998789  样本处理速率： 295.1267162144334  examples/sec 迭代消耗时间： 0.4337120056152344 s
迭代轮数： 2150  损失值loss： 1.13093  样本处理速率： 289.69704648408305  examples/sec 迭代消耗时间： 0.44184088706970215 s
迭代轮数： 2160  损失值loss： 1.18447  样本处理速率： 283.4183680256774  examples/sec 迭代消耗时间： 0.4516291618347168 s
迭代轮数： 2170  损失值loss： 1.22682  样本处理速率： 288.7228562147883  examples/sec 迭代消耗时间： 0.4433317184448242 s
迭代轮数： 2180  损失值loss： 1.16259  样本处理速率： 287.4002821161387  examples/sec 迭代消耗时间： 0.4453718662261963 s
迭代轮数： 2190  损失值loss： 1.20653  样本处理速率： 292.003337361809  examples/sec 迭代消耗时间： 0.4383511543273926 s
迭代轮数： 2200  损失值loss： 1.05103  样本处理速率： 281.7439113988354  examples/sec 迭代消耗时间： 0.4543132781982422 s
迭代轮数： 2210  损失值loss： 1.11862  样本处理速率： 287.04762393601095  examples/sec 迭代消耗时间： 0.4459190368652344 s
迭代轮数： 2220  损失值loss： 1.20639  样本处理速率： 271.6020644696517  examples/sec 迭代消耗时间： 0.47127771377563477 s
迭代轮数： 2230  损失值loss： 0.999843  样本处理速率： 292.3990174773568  examples/sec 迭代消耗时间： 0.4377579689025879 s
迭代轮数： 2240  损失值loss： 0.931342  样本处理速率： 286.5123816985037  examples/sec 迭代消耗时间： 0.44675207138061523 s
迭代轮数： 2250  损失值loss： 0.939245  样本处理速率： 286.8586670314263  examples/sec 迭代消耗时间： 0.4462127685546875 s
迭代轮数： 2260  损失值loss： 1.01696  样本处理速率： 291.3574181588079  examples/sec 迭代消耗时间： 0.43932294845581055 s
迭代轮数： 2270  损失值loss： 1.18007  样本处理速率： 291.32563983601534  examples/sec 迭代消耗时间： 0.43937087059020996 s
迭代轮数： 2280  损失值loss： 1.27315  样本处理速率： 287.89206545998195  examples/sec 迭代消耗时间： 0.4446110725402832 s
迭代轮数： 2290  损失值loss： 1.03799  样本处理速率： 288.75500104611456  examples/sec 迭代消耗时间： 0.4432823657989502 s
迭代轮数： 2300  损失值loss： 0.953317  样本处理速率： 287.2686447130663  examples/sec 迭代消耗时间： 0.4455759525299072 s
迭代轮数： 2310  损失值loss： 1.18191  样本处理速率： 293.60488124737157  examples/sec 迭代消耗时间： 0.435960054397583 s
迭代轮数： 2320  损失值loss： 1.21682  样本处理速率： 290.5750992495731  examples/sec 迭代消耗时间： 0.4405057430267334 s
迭代轮数： 2330  损失值loss： 1.12057  样本处理速率： 288.0281380485452  examples/sec 迭代消耗时间： 0.4444010257720947 s
迭代轮数： 2340  损失值loss： 1.0488  样本处理速率： 287.4195149633278  examples/sec 迭代消耗时间： 0.4453420639038086 s
迭代轮数： 2350  损失值loss： 1.05333  样本处理速率： 296.438193511909  examples/sec 迭代消耗时间： 0.431793212890625 s
迭代轮数： 2360  损失值loss： 1.07586  样本处理速率： 292.86269401363637  examples/sec 迭代消耗时间： 0.43706488609313965 s
迭代轮数： 2370  损失值loss： 1.02044  样本处理速率： 287.7808008876715  examples/sec 迭代消耗时间： 0.44478297233581543 s
迭代轮数： 2380  损失值loss： 1.0445  样本处理速率： 289.9483163021999  examples/sec 迭代消耗时间： 0.44145798683166504 s
迭代轮数： 2390  损失值loss： 0.918307  样本处理速率： 294.51085837917543  examples/sec 迭代消耗时间： 0.4346189498901367 s
迭代轮数： 2400  损失值loss： 1.17024  样本处理速率： 280.8306173743608  examples/sec 迭代消耗时间： 0.45579075813293457 s
迭代轮数： 2410  损失值loss： 1.03276  样本处理速率： 287.0393365177232  examples/sec 迭代消耗时间： 0.44593191146850586 s
迭代轮数： 2420  损失值loss： 1.15965  样本处理速率： 285.54472482187725  examples/sec 迭代消耗时间： 0.44826602935791016 s
迭代轮数： 2430  损失值loss： 0.913365  样本处理速率： 285.0488134711312  examples/sec 迭代消耗时间： 0.44904589653015137 s
迭代轮数： 2440  损失值loss： 1.07698  样本处理速率： 288.8379584522095  examples/sec 迭代消耗时间： 0.44315505027770996 s
迭代轮数： 2450  损失值loss： 1.00573  样本处理速率： 291.9973023187006  examples/sec 迭代消耗时间： 0.43836021423339844 s
迭代轮数： 2460  损失值loss： 1.21657  样本处理速率： 289.26421507035604  examples/sec 迭代消耗时间： 0.4425020217895508 s
迭代轮数： 2470  损失值loss： 0.923855  样本处理速率： 289.68250932926424  examples/sec 迭代消耗时间： 0.4418630599975586 s
迭代轮数： 2480  损失值loss： 0.933499  样本处理速率： 287.47245705081934  examples/sec 迭代消耗时间： 0.44526004791259766 s
迭代轮数： 2490  损失值loss： 0.978734  样本处理速率： 274.2586528465647  examples/sec 迭代消耗时间： 0.46671271324157715 s
迭代轮数： 2500  损失值loss： 0.937915  样本处理速率： 292.3377187274534  examples/sec 迭代消耗时间： 0.437849760055542 s
迭代轮数： 2510  损失值loss： 1.13114  样本处理速率： 288.8561408794744  examples/sec 迭代消耗时间： 0.4431271553039551 s
迭代轮数： 2520  损失值loss： 1.05186  样本处理速率： 286.9807243702546  examples/sec 迭代消耗时间： 0.44602298736572266 s
迭代轮数： 2530  损失值loss： 0.955211  样本处理速率： 288.00866916048085  examples/sec 迭代消耗时间： 0.4444310665130615 s
迭代轮数： 2540  损失值loss： 1.10109  样本处理速率： 287.7609027037805  examples/sec 迭代消耗时间： 0.44481372833251953 s
迭代轮数： 2550  损失值loss： 1.10622  样本处理速率： 292.01874373463744  examples/sec 迭代消耗时间： 0.4383280277252197 s
迭代轮数： 2560  损失值loss： 1.13482  样本处理速率： 289.4048642488812  examples/sec 迭代消耗时间： 0.44228696823120117 s
迭代轮数： 2570  损失值loss： 1.46149  样本处理速率： 289.4363809273248  examples/sec 迭代消耗时间： 0.44223880767822266 s
迭代轮数： 2580  损失值loss： 1.08592  样本处理速率： 284.92552049887223  examples/sec 迭代消耗时间： 0.44924020767211914 s
迭代轮数： 2590  损失值loss： 0.984867  样本处理速率： 284.49249702456336  examples/sec 迭代消耗时间： 0.4499239921569824 s
迭代轮数： 2600  损失值loss： 0.931783  样本处理速率： 288.6874585953833  examples/sec 迭代消耗时间： 0.4433860778808594 s
迭代轮数： 2610  损失值loss： 1.18123  样本处理速率： 293.9400459029031  examples/sec 迭代消耗时间： 0.43546295166015625 s
迭代轮数： 2620  损失值loss： 1.17834  样本处理速率： 287.78404038736363  examples/sec 迭代消耗时间： 0.4447779655456543 s
迭代轮数： 2630  损失值loss： 1.21732  样本处理速率： 289.8072949673686  examples/sec 迭代消耗时间： 0.44167280197143555 s
迭代轮数： 2640  损失值loss： 1.0131  样本处理速率： 289.154379318498  examples/sec 迭代消耗时间： 0.4426701068878174 s
迭代轮数： 2650  损失值loss： 1.04736  样本处理速率： 288.3952943198788  examples/sec 迭代消耗时间： 0.4438352584838867 s
迭代轮数： 2660  损失值loss： 1.16725  样本处理速率： 285.17690903325155  examples/sec 迭代消耗时间： 0.44884419441223145 s
迭代轮数： 2670  损失值loss： 0.882673  样本处理速率： 285.1223862143903  examples/sec 迭代消耗时间： 0.448930025100708 s
迭代轮数： 2680  损失值loss： 1.12734  样本处理速率： 293.20753435094076  examples/sec 迭代消耗时间： 0.4365508556365967 s
迭代轮数： 2690  损失值loss： 1.2743  样本处理速率： 286.85652122340326  examples/sec 迭代消耗时间： 0.4462161064147949 s
迭代轮数： 2700  损失值loss： 1.18258  样本处理速率： 292.2907669441465  examples/sec 迭代消耗时间： 0.43792009353637695 s
迭代轮数： 2710  损失值loss： 1.04315  样本处理速率： 292.6642513789054  examples/sec 迭代消耗时间： 0.4373612403869629 s
迭代轮数： 2720  损失值loss： 1.20337  样本处理速率： 294.4722506983742  examples/sec 迭代消耗时间： 0.434675931930542 s
迭代轮数： 2730  损失值loss： 1.10764  样本处理速率： 286.8591268516079  examples/sec 迭代消耗时间： 0.4462120532989502 s
迭代轮数： 2740  损失值loss： 1.05413  样本处理速率： 285.9593296822585  examples/sec 迭代消耗时间： 0.4476161003112793 s
迭代轮数： 2750  损失值loss： 0.996761  样本处理速率： 289.68641702319616  examples/sec 迭代消耗时间： 0.44185709953308105 s
迭代轮数： 2760  损失值loss： 0.943409  样本处理速率： 273.43535824315524  examples/sec 迭代消耗时间： 0.46811795234680176 s
迭代轮数： 2770  损失值loss： 0.990517  样本处理速率： 282.6960586801186  examples/sec 迭代消耗时间： 0.45278310775756836 s
迭代轮数： 2780  损失值loss： 1.21229  样本处理速率： 283.7840587072087  examples/sec 迭代消耗时间： 0.4510471820831299 s
迭代轮数： 2790  损失值loss： 1.07727  样本处理速率： 286.24199822561934  examples/sec 迭代消耗时间： 0.447174072265625 s
迭代轮数： 2800  损失值loss： 1.0535  样本处理速率： 290.9878904755246  examples/sec 迭代消耗时间： 0.4398808479309082 s
迭代轮数： 2810  损失值loss： 1.1167  样本处理速率： 290.5181785271137  examples/sec 迭代消耗时间： 0.44059205055236816 s
迭代轮数： 2820  损失值loss： 0.93803  样本处理速率： 288.68419872485975  examples/sec 迭代消耗时间： 0.4433910846710205 s
迭代轮数： 2830  损失值loss： 0.990584  样本处理速率： 288.188934212172  examples/sec 迭代消耗时间： 0.4441530704498291 s
迭代轮数： 2840  损失值loss： 1.07101  样本处理速率： 274.94604077247175  examples/sec 迭代消耗时间： 0.4655458927154541 s
迭代轮数： 2850  损失值loss： 1.07867  样本处理速率： 289.4112606432728  examples/sec 迭代消耗时间： 0.442277193069458 s
迭代轮数： 2860  损失值loss： 0.94567  样本处理速率： 285.65806648654  examples/sec 迭代消耗时间： 0.4480881690979004 s
迭代轮数： 2870  损失值loss： 1.08691  样本处理速率： 288.480680311806  examples/sec 迭代消耗时间： 0.44370388984680176 s
迭代轮数： 2880  损失值loss： 0.929185  样本处理速率： 276.08110816908044  examples/sec 迭代消耗时间： 0.46363186836242676 s
迭代轮数： 2890  损失值loss： 0.982743  样本处理速率： 273.08430669502275  examples/sec 迭代消耗时间： 0.4687197208404541 s
迭代轮数： 2900  损失值loss： 1.03645  样本处理速率： 233.28196362012042  examples/sec 迭代消耗时间： 0.5486922264099121 s
迭代轮数： 2910  损失值loss： 1.14443  样本处理速率： 274.0981875047545  examples/sec 迭代消耗时间： 0.46698594093322754 s
迭代轮数： 2920  损失值loss： 1.09655  样本处理速率： 267.7946234660458  examples/sec 迭代消耗时间： 0.4779782295227051 s
迭代轮数： 2930  损失值loss： 1.02765  样本处理速率： 239.72781091510524  examples/sec 迭代消耗时间： 0.5339388847351074 s
迭代轮数： 2940  损失值loss： 1.04568  样本处理速率： 242.13619624873772  examples/sec 迭代消耗时间： 0.5286281108856201 s
迭代轮数： 2950  损失值loss： 1.04053  样本处理速率： 283.73186652200087  examples/sec 迭代消耗时间： 0.4511301517486572 s
迭代轮数： 2960  损失值loss： 1.16996  样本处理速率： 284.0462096109007  examples/sec 迭代消耗时间： 0.45063090324401855 s
迭代轮数： 2970  损失值loss： 0.901791  样本处理速率： 288.8679529134253  examples/sec 迭代消耗时间： 0.44310903549194336 s
迭代轮数： 2980  损失值loss： 1.10311  样本处理速率： 270.0352800164575  examples/sec 迭代消耗时间： 0.4740121364593506 s
迭代轮数： 2990  损失值loss： 1.32641  样本处理速率： 292.38436712700593  examples/sec 迭代消耗时间： 0.43777990341186523 s
最终准确率：0.703
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="六、AlexNet-（2012）">六、AlexNet （2012）<a class="anchor-link" href="#六、AlexNet-（2012）">¶</a></h3><p>AlexNet以绝对优势拿下 ILSVRC 2012 冠军，引起了学术界的极大关注，为复兴神经网络做出了很大贡献。 当然，也需要有ImageNet这样的超大训练集来进行训练以避免过拟合。</p>
<p>应用 CNN 的计算瓶颈主要是训练过程（backward）。预测过程（forward）一般计算量不大，可以在移动端运行。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="七、VGGNet-（2014）">七、VGGNet （2014）<a class="anchor-link" href="#七、VGGNet-（2014）">¶</a></h3><p>VGGNet 现在依然经常被用来提取图像特征。VGGNet训练后的模型参数在其官方网站开源了，可以进行再训练（相当于提供了非常好的初始化权重），被用在了很多地方。</p>
<p>其模型参数虽然比 AlexNet 多，但反而只需要较少的迭代次数就可以收敛，主要原因是更深的网络和更小的卷积核带来的隐式的正则化效果。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="八、Google-Inception-Net-（2014）">八、Google Inception Net （2014）<a class="anchor-link" href="#八、Google-Inception-Net-（2014）">¶</a></h3><p>V1 V2 V3 V4  参见4篇论文</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="九、ResNet-（2015，微软研究院，152层）">九、ResNet （2015，微软研究院，152层）<a class="anchor-link" href="#九、ResNet-（2015，微软研究院，152层）">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="十、实现-Word2Vec-（2013，google）">十、实现 Word2Vec （2013，google）<a class="anchor-link" href="#十、实现-Word2Vec-（2013，google）">¶</a></h3><p>图片、语音天然就是稠密向量。但一篇文章如果不处理会是一个稀疏矩阵。Word2Vec 将语言中的字词转化为机器可以理解的稠密向量（Dense Vector），进而可以进行文本分类、词性标注、机器翻译等自然语言处理任务。</p>
<p>循环神经网络（RNN）是自然语言处理领域最常用的神经网络结构，其地位和卷积神经网络（CNN）在图像识别领域的地位类似。</p>
<p>Word2Vec 的基本思想是把自然语言中的每一个词，表示成一个统一意义统一维度的短向量。至于向量中的每个维度具体是什么意义，没人知道，也无需知道，也许对应于世界上的一些最基本的概念。一个人读书时，如果遇到了生僻的词，一般能根据上下文大概猜出生僻词的意思，而 Word2Vec 正是很好的捕捉了这种人类的行为，利用神经元网络模型，发现了自然语言处理的一颗原子弹。</p>
<p>对词汇表中所有的样本（One-Hot的向量），训练这个神经元网络。收敛之后，将从输入层到隐含层的那些权重，作为每一个词汇表中的词的向量。有了每个词的有限维度的向量，就可以用到其它的应用中，因为它们就像图像，有了有限维度的统一意义的输入。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">urllib</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">'http://mattmahoney.net/dc/'</span>
<span class="k">def</span> <span class="nf">maybe_download</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">expected_bytes</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Downloading...'</span><span class="p">)</span>
        <span class="n">filename</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span> <span class="o">+</span> <span class="n">filename</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="n">statinfo</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">stat</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">statinfo</span><span class="o">.</span><span class="n">st_size</span> <span class="o">==</span> <span class="n">expected_bytes</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Found and verified '</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Fail to verify, you can get it by using a browser'</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">filename</span>

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">as_str</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">namelist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'程序启动'</span><span class="p">)</span>
<span class="n">filename</span> <span class="o">=</span> <span class="n">maybe_download</span><span class="p">(</span><span class="s1">'text8.zip'</span><span class="p">,</span> <span class="mi">31344016</span><span class="p">)</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'单词数量：'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>

<span class="n">vocabulary_size</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="k">def</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="n">count</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">'UNK'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]</span>   <span class="c1"># top50000 以外的词汇标记成 unkown</span>
    <span class="n">count</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">vocabulary_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">count</span><span class="p">:</span>
        <span class="n">dictionary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="n">unk_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">unk_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
    <span class="n">count</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">unk_count</span>
    <span class="n">reverse_dictionary</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span>

<span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span> <span class="o">=</span> <span class="n">build_dataset</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="k">del</span> <span class="n">words</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'最高频词汇：'</span><span class="p">,</span> <span class="n">count</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'样本数据：'</span><span class="p">,</span> <span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span> <span class="p">])</span>

<span class="n">data_index</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">def</span> <span class="nf">generate_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_skips</span><span class="p">,</span> <span class="n">skip_window</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">data_index</span>
    <span class="k">assert</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">num_skips</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">num_skips</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">skip_window</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">span</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">skip_window</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">buffer</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">span</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">span</span><span class="p">):</span>
        <span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_index</span><span class="p">])</span>
        <span class="n">data_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="n">num_skips</span><span class="p">):</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">skip_window</span>
        <span class="n">targets_to_avoid</span> <span class="o">=</span> <span class="p">[</span><span class="n">skip_window</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_skips</span><span class="p">):</span>
            <span class="k">while</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">targets_to_avoid</span><span class="p">:</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">span</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">targets_to_avoid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
            <span class="n">batch</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">num_skips</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="n">skip_window</span><span class="p">]</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">num_skips</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
        <span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data_index</span><span class="p">])</span>
        <span class="n">data_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span><span class="p">,</span> <span class="n">labels</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">skip_window</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_skips</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">valid_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">valid_window</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">valid_examples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">valid_window</span><span class="p">,</span> <span class="n">valid_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">num_sampled</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># 定义网络结构</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">train_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
    <span class="n">train_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">valid_examples</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'/cpu:0'</span><span class="p">):</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">train_inputs</span><span class="p">)</span>
        <span class="n">nce_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span><span class="o">/</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">nce_biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">vocabulary_size</span><span class="p">]))</span>
        
    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">nce_loss</span><span class="p">(</span>
        <span class="n">weights</span><span class="o">=</span><span class="n">nce_weights</span><span class="p">,</span>
        <span class="n">biases</span> <span class="o">=</span> <span class="n">nce_biases</span><span class="p">,</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">,</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">embed</span><span class="p">,</span>
        <span class="n">num_sampled</span> <span class="o">=</span> <span class="n">num_sampled</span><span class="p">,</span>
        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">vocabulary_size</span>
    <span class="p">))</span> 
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">embeddings</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">normalized_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">/</span> <span class="n">norm</span>
    <span class="n">valid_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">normalized_embeddings</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">)</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">valid_embeddings</span><span class="p">,</span> <span class="n">normalized_embeddings</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
    

<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100001</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
    <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'初始化完成'</span><span class="p">)</span>
    <span class="n">average_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
        <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">generate_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_skips</span><span class="p">,</span> <span class="n">skip_window</span><span class="p">)</span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">train_inputs</span><span class="p">:</span> <span class="n">batch_inputs</span><span class="p">,</span>
            <span class="n">train_labels</span><span class="p">:</span> <span class="n">batch_labels</span>
        <span class="p">}</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss_val</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="n">average_loss</span> <span class="o">+=</span> <span class="n">loss_val</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">2000</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">average_loss</span> <span class="o">/=</span> <span class="mi">2000</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'第'</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span><span class="s1">'轮迭代后的平均损失：'</span><span class="p">,</span> <span class="n">average_loss</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">10000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sim</span> <span class="o">=</span> <span class="n">similarity</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_size</span><span class="p">):</span>
                <span class="n">valid_word</span> <span class="o">=</span> <span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">valid_examples</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                <span class="n">top_k</span> <span class="o">=</span> <span class="mi">8</span>
                <span class="n">nearest</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">sim</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="n">top_k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">log_str</span> <span class="o">=</span> <span class="s2">"最靠近单词 </span><span class="si">%s</span><span class="s2"> 的词汇："</span> <span class="o">%</span> <span class="p">(</span><span class="n">valid_word</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">top_k</span><span class="p">):</span>
                    <span class="n">close_word</span> <span class="o">=</span> <span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">nearest</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span>
                    <span class="n">log_str</span> <span class="o">=</span> <span class="s2">"</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">,"</span> <span class="o">%</span><span class="p">(</span><span class="n">log_str</span><span class="p">,</span> <span class="n">close_word</span><span class="p">)</span>
                <span class="nb">print</span> <span class="p">(</span><span class="n">log_str</span><span class="p">)</span>
            
    <span class="n">final_embeddings</span> <span class="o">=</span> <span class="n">normalized_embeddings</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>程序启动
Found and verified  text8.zip
单词数量： 17005207
最高频词汇： [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]
样本数据： [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']
WARNING:tensorflow:From &lt;ipython-input-1-db9e65b69732&gt;:119: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
初始化完成
最靠近单词 b 的词汇： rabbit, ecuadorean, contract, connors, neanderthal, frequently, showcases, apes,
最靠近单词 no 的词汇： soir, janus, creditor, enlists, honed, sealing, gael, picatinny,
最靠近单词 it 的词汇： misdemeanor, overturned, murdock, vom, giuseppe, annie, wilfred, disestablished,
最靠近单词 their 的词汇： usgs, daniel, magneto, micrometres, mathrm, effective, housewife, sutter,
最靠近单词 after 的词汇： speed, reflux, shipwrecked, initiative, sinful, daemen, fianna, documenting,
最靠近单词 years 的词汇： crusades, vega, lilies, hoare, sukhoi, imitated, stratum, simulcast,
最靠近单词 three 的词汇： teutoburg, nobita, horrific, piedmont, diogo, planted, opencyc, leper,
最靠近单词 new 的词汇： intensified, cockney, paved, geocaching, coefficient, gloomy, karl, intimate,
最靠近单词 may 的词汇： adventures, amygdala, aggregate, inwards, terracotta, enlarged, iib, supposed,
最靠近单词 has 的词汇： lavender, cabinet, pediment, malinche, dishes, portman, grey, plainly,
最靠近单词 system 的词汇： neutralize, decoys, incompleteness, majdanek, iud, enhancement, hallucinogen, giger,
最靠近单词 called 的词汇： quarters, revolted, shamash, unimpressed, rove, plc, pet, gysin,
最靠近单词 to 的词汇： flogging, beatification, poisonous, oxidizing, shakti, promoted, iraqi, prostaglandin,
最靠近单词 or 的词汇： devious, orestes, extractive, demarcation, christophe, robberies, invertebrates, italia,
最靠近单词 were 的词汇： beersheba, formulating, nineveh, mjt, strove, hakim, princesses, withdrawing,
最靠近单词 some 的词汇： outdoor, sustainable, enforce, diversify, caenorhabditis, tuva, denham, gains,
第 2000 轮迭代后的平均损失： 113.402473411
第 4000 轮迭代后的平均损失： 52.6376713691
第 6000 轮迭代后的平均损失： 33.671081387
第 8000 轮迭代后的平均损失： 23.3774275388
第 10000 轮迭代后的平均损失： 18.389942677
最靠近单词 b 的词汇： rabbit, handwriting, argon, contract, connors, pedro, jutsu, deep,
最靠近单词 no 的词汇： five, soir, cl, gland, students, traffic, door, refugee,
最靠近单词 it 的词汇： reginae, he, and, who, project, annie, armies, lm,
最靠近单词 their 的词汇： the, a, effective, this, daniel, fao, usgs, gland,
最靠近单词 after 的词汇： initiative, phi, speed, and, winning, gollancz, burt, sinful,
最靠近单词 years 的词汇： gland, austin, crusades, hoare, things, vs, updated, vega,
最靠近单词 three 的词汇： nine, two, five, gollancz, asymmetric, austin, one, reginae,
最靠近单词 new 的词汇： reginae, scientists, ottoman, archie, parliament, doctors, scheduling, hephaestus,
最靠近单词 may 的词汇： catch, amygdala, provincial, reginae, adventures, measure, rfcs, supposed,
最靠近单词 has 的词汇： cabinet, grey, relations, better, seeds, alpina, pushed, jets,
最靠近单词 system 的词汇： vs, analysis, incompleteness, enhancement, americans, loved, own, opens,
最靠近单词 called 的词汇： austin, quarters, pet, reginae, scientist, picked, resembles, rotate,
最靠近单词 to 的词汇： uh, and, hydrochloric, in, nine, amo, reginae, mcdowell,
最靠近单词 or 的词汇： and, victoriae, austin, reginae, anschluss, phobias, rotors, zero,
最靠近单词 were 的词汇： put, and, are, alpina, also, shorthand, seemingly, android,
最靠近单词 some 的词汇： outdoor, sustainable, alpina, gains, cast, the, a, oxidation,
第 12000 轮迭代后的平均损失： 14.294583536
第 14000 轮迭代后的平均损失： 11.6797207339
第 16000 轮迭代后的平均损失： 9.90035084979
第 18000 轮迭代后的平均损失： 8.65827149107
第 20000 轮迭代后的平均损失： 7.79248245832
最靠近单词 b 的词汇： d, rabbit, and, handwriting, participation, connors, accomplished, argon,
最靠近单词 no 的词汇： who, five, a, it, soir, polyhedra, cl, refugee,
最靠近单词 it 的词汇： he, reginae, who, they, dasyprocta, which, there, this,
最靠近单词 their 的词汇： the, this, his, a, its, effective, segment, agouti,
最靠近单词 after 的词汇： initiative, and, before, phi, agouti, speed, with, uncovered,
最靠近单词 years 的词汇： gland, crusades, hoare, things, three, vega, repeatedly, vs,
最靠近单词 three 的词汇： five, two, four, zero, nine, six, eight, dasyprocta,
最靠近单词 new 的词汇： reginae, scientists, ottoman, parliament, agouti, archie, hephaestus, scheduling,
最靠近单词 may 的词汇： catch, rfcs, would, amygdala, provincial, reginae, churchman, aggregate,
最靠近单词 has 的词汇： was, is, cabinet, dasyprocta, better, dishes, grey, relations,
最靠近单词 system 的词汇： agouti, incompleteness, polyhedra, analysis, vs, opens, enhancement, loved,
最靠近单词 called 的词汇： austin, quarters, scientist, glorified, without, pet, reginae, picked,
最靠近单词 to 的词汇： and, for, uh, hydrochloric, sampras, nine, flogging, with,
最靠近单词 or 的词汇： and, zero, victoriae, eight, agouti, anschluss, reginae, nine,
最靠近单词 were 的词汇： are, is, was, and, put, vicksburg, in, by,
最靠近单词 some 的词汇： outdoor, alpina, the, agouti, sustainable, his, this, interpret,
第 22000 轮迭代后的平均损失： 7.13775973431
第 24000 轮迭代后的平均损失： 6.95369413855
第 26000 轮迭代后的平均损失： 6.60301392724
第 28000 轮迭代后的平均损失： 6.24016572389
第 30000 轮迭代后的平均损失： 6.16963108689
最靠近单词 b 的词汇： d, rabbit, handwriting, participation, and, connors, capitolina, argon,
最靠近单词 no 的词汇： who, a, it, creditor, abiword, five, ramps, door,
最靠近单词 it 的词汇： he, reginae, this, they, there, who, which, dasyprocta,
最靠近单词 their 的词汇： the, his, its, this, a, aargau, segment, her,
最靠近单词 after 的词汇： before, and, initiative, phi, from, with, at, agouti,
最靠近单词 years 的词汇： gland, crusades, hoare, things, three, vega, stratum, repeatedly,
最靠近单词 three 的词汇： five, four, six, eight, two, nine, seven, zero,
最靠近单词 new 的词汇： reginae, scientists, ottoman, anoa, parliament, scheduling, sarai, doctors,
最靠近单词 may 的词汇： would, rfcs, catch, zero, could, aggregate, cyclase, churchman,
最靠近单词 has 的词汇： was, is, had, have, maus, dasyprocta, initiates, better,
最靠近单词 system 的词汇： agouti, incompleteness, relating, polyhedra, opens, dasyprocta, analysis, neutralize,
最靠近单词 called 的词汇： austin, quarters, glorified, without, shamash, scientist, reginae, pet,
最靠近单词 to 的词汇： for, in, and, with, from, nine, uh, hydrochloric,
最靠近单词 or 的词汇： and, victoriae, agouti, reginae, austin, vpi, dasyprocta, abitibi,
最靠近单词 were 的词汇： are, was, is, by, have, put, vicksburg, nineveh,
最靠近单词 some 的词汇： many, the, these, this, alpina, outdoor, agouti, agp,
第 32000 轮迭代后的平均损失： 5.85607265453
第 34000 轮迭代后的平均损失： 5.84302328896
第 36000 轮迭代后的平均损失： 5.67487581658
第 38000 轮迭代后的平均损失： 5.23110571877
第 40000 轮迭代后的平均损失： 5.4866200598
最靠近单词 b 的词汇： d, rabbit, peanuts, and, UNK, recitative, four, handwriting,
最靠近单词 no 的词汇： who, a, creditor, abiword, it, households, five, particularly,
最靠近单词 it 的词汇： he, reginae, this, there, they, which, dasyprocta, not,
最靠近单词 their 的词汇： the, its, his, her, this, a, segment, aargau,
最靠近单词 after 的词汇： before, from, initiative, phi, with, at, and, four,
最靠近单词 years 的词汇： gland, hoare, crusades, things, vega, stratum, rejecting, repeatedly,
最靠近单词 three 的词汇： four, five, six, two, eight, seven, zero, nine,
最靠近单词 new 的词汇： reginae, scientists, ottoman, parliament, scheduling, anoa, agouti, doctors,
最靠近单词 may 的词汇： would, can, rfcs, could, will, catch, aggregate, churchman,
最靠近单词 has 的词汇： was, is, had, have, maus, dasyprocta, initiates, handlers,
最靠近单词 system 的词汇： agouti, polyhedra, dasyprocta, relating, opens, alphorn, incompleteness, pasadena,
最靠近单词 called 的词汇： austin, quarters, without, glorified, shamash, reginae, amo, rotate,
最靠近单词 to 的词汇： for, can, nine, from, with, amo, uh, hydrochloric,
最靠近单词 or 的词汇： and, eight, agouti, victoriae, nine, four, six, abet,
最靠近单词 were 的词汇： are, was, have, is, by, been, put, vicksburg,
最靠近单词 some 的词汇： many, these, the, alpina, this, agouti, outdoor, their,
第 42000 轮迭代后的平均损失： 5.30927840453
第 44000 轮迭代后的平均损失： 5.31043591245
第 46000 轮迭代后的平均损失： 5.26607571716
第 48000 轮迭代后的平均损失： 5.04188639062
第 50000 轮迭代后的平均损失： 5.16436249879
最靠近单词 b 的词汇： d, four, rabbit, peanuts, recitative, capitolina, three, six,
最靠近单词 no 的词汇： creditor, abiword, a, who, households, five, particularly, governorship,
最靠近单词 it 的词汇： he, this, there, reginae, which, they, dasyprocta, agouti,
最靠近单词 their 的词汇： his, its, the, her, many, some, segment, angiotensin,
最靠近单词 after 的词汇： before, six, from, phi, with, at, and, roshan,
最靠近单词 years 的词汇： gland, hoare, crusades, four, things, thibetanus, maclennan, vega,
最靠近单词 three 的词汇： four, six, five, eight, two, seven, one, nine,
最靠近单词 new 的词汇： reginae, ottoman, scientists, parliament, sarai, scheduling, anoa, hephaestus,
最靠近单词 may 的词汇： would, can, could, will, rfcs, should, abitibi, churchman,
最靠近单词 has 的词汇： had, was, is, have, maus, dasyprocta, initiates, akita,
最靠近单词 system 的词汇： iud, joh, agouti, opens, relating, predicts, couch, incompleteness,
最靠近单词 called 的词汇： austin, quarters, glorified, without, shamash, reginae, UNK, collects,
最靠近单词 to 的词汇： can, nine, for, uh, hydrochloric, not, into, sampras,
最靠近单词 or 的词汇： and, eight, but, agouti, six, recitative, gland, four,
最靠近单词 were 的词汇： are, was, have, is, by, be, been, vicksburg,
最靠近单词 some 的词汇： many, these, the, this, alpina, several, their, agouti,
第 52000 轮迭代后的平均损失： 5.1630863829
第 54000 轮迭代后的平均损失： 5.13757408057
第 56000 轮迭代后的平均损失： 5.04469344884
第 58000 轮迭代后的平均损失： 5.11400745772
第 60000 轮迭代后的平均损失： 4.95756696837
最靠近单词 b 的词汇： d, rabbit, recitative, callithrix, prism, four, pettigrew, peanuts,
最靠近单词 no 的词汇： a, abiword, creditor, households, pulau, who, governorship, particularly,
最靠近单词 it 的词汇： he, this, there, reginae, callithrix, which, they, cebus,
最靠近单词 their 的词汇： its, his, the, her, some, cebus, segment, many,
最靠近单词 after 的词汇： before, during, when, from, callithrix, initiative, at, six,
最靠近单词 years 的词汇： hoare, gland, things, six, crusades, maclennan, thibetanus, rejecting,
最靠近单词 three 的词汇： five, four, six, two, eight, seven, nine, one,
最靠近单词 new 的词汇： reginae, scientists, ottoman, scheduling, sarai, parliament, hephaestus, lipids,
最靠近单词 may 的词汇： would, can, could, will, rfcs, should, must, to,
最靠近单词 has 的词汇： had, was, have, is, dasyprocta, maus, initiates, akita,
最靠近单词 system 的词汇： agouti, callithrix, opens, dasyprocta, polyhedra, iud, joh, alphorn,
最靠近单词 called 的词汇： austin, quarters, cebus, glorified, without, leontopithecus, michelob, shamash,
最靠近单词 to 的词汇： can, nine, callithrix, would, not, will, uh, pulau,
最靠近单词 or 的词汇： and, callithrix, michelob, six, agouti, eight, gland, but,
最靠近单词 were 的词汇： are, was, have, been, had, by, be, is,
最靠近单词 some 的词汇： many, these, several, this, the, their, alpina, other,
第 62000 轮迭代后的平均损失： 4.78235450422
第 64000 轮迭代后的平均损失： 4.7675297807
第 66000 轮迭代后的平均损失： 4.96215016713
第 68000 轮迭代后的平均损失： 4.91078380266
第 70000 轮迭代后的平均损失： 4.77489341082
最靠近单词 b 的词汇： d, rabbit, recitative, four, pettigrew, seven, capitolina, prism,
最靠近单词 no 的词汇： households, a, abiword, creditor, jaffa, governorship, any, pulau,
最靠近单词 it 的词汇： he, this, there, reginae, they, callithrix, which, cebus,
最靠近单词 their 的词汇： its, his, the, her, some, segment, many, cebus,
最靠近单词 after 的词汇： before, during, when, at, initiative, from, callithrix, was,
最靠近单词 years 的词汇： gland, days, thibetanus, hoare, things, three, six, maclennan,
最靠近单词 three 的词汇： five, four, six, seven, two, eight, one, nine,
最靠近单词 new 的词汇： reginae, ottoman, scientists, scheduling, sarai, parliament, hephaestus, cebus,
最靠近单词 may 的词汇： would, can, will, could, should, rfcs, must, might,
最靠近单词 has 的词汇： had, was, have, is, dasyprocta, maus, akita, cebus,
最靠近单词 system 的词汇： agouti, iud, opens, callithrix, polyhedra, alphorn, joh, dasyprocta,
最靠近单词 called 的词汇： austin, glorified, quarters, cebus, UNK, shamash, without, michelob,
最靠近单词 to 的词汇： can, would, will, not, callithrix, for, uh, michelob,
最靠近单词 or 的词汇： and, michelob, callithrix, agouti, but, gland, dasyprocta, recitative,
最靠近单词 were 的词汇： are, was, have, had, been, those, be, is,
最靠近单词 some 的词汇： many, these, several, the, other, their, both, this,
第 72000 轮迭代后的平均损失： 4.80552351743
第 74000 轮迭代后的平均损失： 4.77244276488
第 76000 轮迭代后的平均损失： 4.87844171533
第 78000 轮迭代后的平均损失： 4.81217618794
第 80000 轮迭代后的平均损失： 4.81088421069
最靠近单词 b 的词汇： d, four, recitative, rabbit, pettigrew, three, capitolina, prism,
最靠近单词 no 的词汇： households, abiword, polyhedra, pulau, any, creditor, jaffa, governorship,
最靠近单词 it 的词汇： he, this, there, reginae, they, which, callithrix, dasyprocta,
最靠近单词 their 的词汇： its, his, the, her, some, segment, cebus, many,
最靠近单词 after 的词汇： before, during, when, at, from, callithrix, in, pontificia,
最靠近单词 years 的词汇： days, gland, hoare, goldbach, thibetanus, things, four, three,
最靠近单词 three 的词汇： four, five, six, two, seven, eight, one, cegep,
最靠近单词 new 的词汇： reginae, scheduling, ottoman, parliament, scientists, sarai, escuela, smyrna,
最靠近单词 may 的词汇： would, can, will, could, should, must, might, rfcs,
最靠近单词 has 的词汇： had, was, have, is, dasyprocta, maus, akita, capitan,
最靠近单词 system 的词汇： cegep, agouti, opens, iud, callithrix, masked, polyhedra, dasyprocta,
最靠近单词 called 的词汇： austin, glorified, cebus, quarters, michelob, leontopithecus, reginae, kon,
最靠近单词 to 的词汇： nine, will, callithrix, can, for, uh, would, amo,
最靠近单词 or 的词汇： and, michelob, callithrix, cegep, agouti, but, dasyprocta, than,
最靠近单词 were 的词汇： are, was, have, had, been, those, be, being,
最靠近单词 some 的词汇： many, these, several, other, both, this, the, alpina,
第 82000 轮迭代后的平均损失： 4.80176780199
第 84000 轮迭代后的平均损失： 4.77369988667
第 86000 轮迭代后的平均损失： 4.76494850368
第 88000 轮迭代后的平均损失： 4.68486653418
第 90000 轮迭代后的平均损失： 4.74090447372
最靠近单词 b 的词汇： d, four, recitative, rabbit, six, pettigrew, three, prism,
最靠近单词 no 的词汇： households, any, abiword, a, polyhedra, pulau, jaffa, frequently,
最靠近单词 it 的词汇： he, this, there, they, reginae, she, which, callithrix,
最靠近单词 their 的词汇： its, his, her, the, some, cebus, many, segment,
最靠近单词 after 的词汇： before, during, when, at, callithrix, pontificia, branching, in,
最靠近单词 years 的词汇： days, things, goldbach, hoare, gland, thibetanus, decades, four,
最靠近单词 three 的词汇： four, two, five, six, seven, eight, cegep, one,
最靠近单词 new 的词汇： reginae, scheduling, ottoman, escuela, schemes, tamias, hephaestus, scientists,
最靠近单词 may 的词汇： can, would, will, could, should, might, must, rfcs,
最靠近单词 has 的词汇： had, have, was, is, dasyprocta, maus, akita, capitan,
最靠近单词 system 的词汇： cegep, agouti, callithrix, tamias, polyhedra, dasyprocta, microcebus, opens,
最靠近单词 called 的词汇： austin, glorified, cebus, michelob, and, reginae, kon, leontopithecus,
最靠近单词 to 的词汇： will, uh, callithrix, can, would, michelob, nine, amo,
最靠近单词 or 的词汇： and, michelob, but, callithrix, cegep, agouti, five, victoriae,
最靠近单词 were 的词汇： are, have, was, had, those, been, be, by,
最靠近单词 some 的词汇： many, these, several, both, this, other, alpina, their,
第 92000 轮迭代后的平均损失： 4.70684363396
第 94000 轮迭代后的平均损失： 4.61518373884
第 96000 轮迭代后的平均损失： 4.74109947725
第 98000 轮迭代后的平均损失： 4.61898290783
第 100000 轮迭代后的平均损失： 4.66517418665
最靠近单词 b 的词汇： d, rabbit, recitative, peanuts, capitolina, pettigrew, wct, guelph,
最靠近单词 no 的词汇： households, any, abiword, jaffa, pulau, polyhedra, a, creditor,
最靠近单词 it 的词汇： he, this, there, she, they, reginae, callithrix, which,
最靠近单词 their 的词汇： its, his, the, her, some, many, cebus, segment,
最靠近单词 after 的词汇： before, during, when, at, callithrix, five, branching, tamias,
最靠近单词 years 的词汇： days, four, goldbach, decades, hoare, things, thibetanus, gland,
最靠近单词 three 的词汇： four, six, five, two, seven, eight, dasyprocta, nine,
最靠近单词 new 的词汇： reginae, scheduling, hephaestus, sarai, survivors, ottoman, scientists, schemes,
最靠近单词 may 的词汇： can, would, will, could, should, might, must, cannot,
最靠近单词 has 的词汇： had, was, have, is, dasyprocta, maus, akita, imran,
最靠近单词 system 的词汇： cegep, agouti, iud, systems, callithrix, opens, polyhedra, tamias,
最靠近单词 called 的词汇： austin, and, glorified, kon, cebus, michelob, leontopithecus, classed,
最靠近单词 to 的词汇： callithrix, will, can, nine, would, uh, michelob, thaler,
最靠近单词 or 的词汇： and, michelob, callithrix, cegep, but, agouti, than, tamias,
最靠近单词 were 的词汇： are, have, was, had, those, being, be, is,
最靠近单词 some 的词汇： many, these, several, both, this, the, their, all,
</pre>
</div>
</div>
</div>
</div>
</div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


        <div class="tags">
        <a href="/tag/ji-qi-xue-xi.html">机器学习</a>
        </div>


    </div>
</div>
        </div></div>
        <div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar">
<div class="widget">
    <form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form">
        <input type="text" name="q" maxlength="20" placeholder="Search"/>
        <input type="hidden" name="sitesearch" value="https://easlslope.cn"/>
    </form>
</div><div class="widget">
    <div class="widget-title">
        <i class="fa fa-folder-o"> Categories</i>
    </div>
    <ul class="category-list">
        <li class="category-list-item"><a class="category-list-link" href="/category/bi-ji.html">笔记</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/ji-suan-ji.html">计算机</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/posts.html">posts</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/xin-qing.html">心情</a></li>
        <li class="category-list-item"><a class="category-list-link" href="/category/yue-du.html">阅读</a></li>
    </ul>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-star-o"> Tags</i></div>
    <div class="tagcloud">
    <a href="/tag/ji-qi-xue-xi.html" style="font-size: 12px">机器学习</a>
    <a href="/tag/go.html" style="font-size: 12px">Go</a>
    <a href="/tag/she-ji-mo-shi.html" style="font-size: 12px">设计模式</a>
    <a href="/tag/python.html" style="font-size: 12px">Python</a>
    <a href="/tag/cc.html" style="font-size: 12px">C/C++</a>
    <a href="/tag/shu-dan.html" style="font-size: 12px">书单</a>
    <a href="/tag/ji-hua.html" style="font-size: 12px">计划</a>
    <a href="/tag/suan-fa.html" style="font-size: 12px">算法</a>
    <a href="/tag/bi-ji.html" style="font-size: 12px">笔记</a>
    <a href="/tag/mian-shi.html" style="font-size: 12px">面试</a>
    <a href="/tag/cao-zuo-xi-tong.html" style="font-size: 12px">操作系统</a>
    <a href="/tag/wang-luo-bian-cheng.html" style="font-size: 12px">网络编程</a>
    <a href="/tag/shu-ju-jie-gou.html" style="font-size: 12px">数据结构</a>
    </div>
</div><div class="widget">
    <div class="widget-title"><i class="fa fa-file-o"> Recent</i></div>
    <ul class="post-list">
        <li class="post-list-item">
        <a class="post-list-link" href="/jupyter_test.html">Jupyter notebook test</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/go_forward_proxy.html">（译文）如何用go语言实现正向代理</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/design-pattern.html">设计模式的梳理与实现</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/booklist.html">2018阅读书单</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/sort-algo.html">排序算法的梳理与实现</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/search-algo.html">查找算法的梳理与实现</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/reference.html">工作笔记</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/interview.html">典型面试题</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/summary3.html">操作系统与网络编程知识梳理</a>
        </li>
        <li class="post-list-item">
        <a class="post-list-link" href="/summary2.html">数据结构与算法知识梳理</a>
        </li>
    </ul>
</div>        </div></div>
        <div class="pure-u-1 pure-u-md-3-4">
<div id="footer">Copyright © 2018 <a href="/." rel="nofollow">东坡烟尘.</a> <a rel="nofollow", target="_blank" href="http://www.miitbeian.gov.cn/">粤ICP备18073435号</a>
    <br><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44030502002132" style="display:inline-block;text-decoration:none;"><img src="/static/beian.png" style="float:left;"/><p style="float:left;height:20px;line-height:20px;margin: 0px 0px 0px 5px;">粤公网安备 44030502002132号</p></a>
    <br>Powered by <a rel="nofollow" target="_blank" href="https://getpelican.com/">Pelican</a> and <a rel="nofollow", target="_blank", href="https://github.com/wormtooth/maupassant-pelican">maupassant</a>.   </div>
        </div>
    </div>
</div>

<a id="rocket" href="#top" class="show"></a>
<script type="text/javascript" src="/theme/js/totop.js" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script>
<script type="text/javascript" src="/theme/js/fancybox.js" async></script>
<link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css" />

</body>
</html>